\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{tocloft}
\usepackage{xcolor} 
\usepackage{float}

\geometry{top=20mm, bottom=20mm, left=25mm, right=25mm}

\lstset{
  language=C++,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\itshape\color{green!50!black},
  stringstyle=\color{red!60!black},
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=8pt,
  backgroundcolor=\color{gray!10},
  showspaces=false,
  showstringspaces=false,
  breaklines=true,
  frame=single,
  tabsize=2,
  captionpos=b
}

\begin{document}

% Титульный лист
\begin{titlepage}
    \centering
    \large
    Министерство науки и высшего образования Российской Федерации\\[0.5cm]
    Федеральное государственное автономное образовательное учреждение высшего образования\\[0.5cm]
    \textbf{«Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»}\\
    (ННГУ)\\[1cm]
    Институт информационных технологий, математики и механики\\[0.5cm]
    Направление подготовки: \textbf{«Программная инженерия»}\\[2cm]

    \vfill % Вертикальное заполнение для центрирования текста
    {\LARGE \textbf{ОТЧЕТ}}\\[0.5cm]
    {\Large по задаче}\\[0.5cm]
    {\LARGE \textbf{«Алгоритм глобального поиска (Стронгина) для одномерных задач оптимизации. 
Распараллеливание по характеристикам»}}\\[0.5cm]
    {\Large \textbf{Вариант №11}}\\[2.5cm]

    \hfill\parbox{0.5\textwidth}{
        \textbf{Выполнил:} \\
        студент группы 3822Б1ПР3 \\
        \textbf{Бурыкин Михаил}
    }\\[0.5cm]

    \hfill\parbox{0.5\textwidth}{
        \textbf{Преподаватели:} \\
        Нестеров А.Ю.\\
        Оболенский А.А.

    }\\[2cm]

    Нижний Новгород\\
    2024
\end{titlepage}

\tableofcontents
\newpage

\section{Введение}

\hspace*{1.25em}Метод Стронгина, известный также как метод локализации глобального поиска, применяется для глобальной оптимизации функций с ограничениями. Этот метод эффективен при минимизации сложных, многомерных функций, обладающих свойствами липшицевости. Основная идея заключается в построении адаптивного покрытия исследуемого пространства для выбора направления поиска.

В данной работе рассматривается программная реализация метода Стронгина с использованием языка программирования C++. Для ускорения вычислений используются методы параллельного программирования, что позволяет уменьшить время выполнения на больших вычислительных задачах.

\section{Постановка задачи}

\hspace*{1.25em}Необходимо реализовать метод Стронгина для поиска глобального минимума заданной функции с ограничениями. Реализация должна включать следующие этапы:

\begin{itemize}
    \item Разработка последовательной версии метода Стронгина для одномерных функций.
    \item Применение параллельных вычислений для ускорения выполнения алгоритма на больших наборах данных.
    \item Проведение функционального тестирования для проверки корректности работы алгоритма.
    \item Сравнение производительности последовательной и параллельной реализаций на наборах данных различной сложности.
\end{itemize}

Целью работы является демонстрация эффективности параллельного подхода к решению задач глобальной оптимизации, а также оценка производительности по времени относительно последовательного подхода.

\section{Описание алгоритма}

\hspace*{1.25em}Алгоритм метода Стронгина состоит из нескольких последовательных этапов, которые выполняются для поиска глобального минимума функции на заданном интервале. Каждый этап включает специфические действия, направленные на адаптацию покрытия пространства поиска.

\begin{enumerate}
    \item \textbf{Предварительная обработка данных}:
    \begin{itemize}
        \item Выполняется инициализация переменных. Извлекаются начальные параметры из входных данных: границы интервала $x_0$, $x_1$, требуемая точность $\varepsilon$.
        \item Проверяется порядок выполнения шагов через вызов функции \texttt{internal\_order\_test}.
    \end{itemize}

    \item \textbf{Валидация данных}:
    \begin{itemize}
        \item Проверяется корректность выходных данных — ожидается, что на выходе будет только одно значение.
        \item Выполняется контроль порядка выполнения через вызов \texttt{internal\_order\_test}.
    \end{itemize}

    \item \textbf{Основной цикл оптимизации}:
    \begin{enumerate}
        \item \textbf{Инициализация начальных точек}:
        \begin{itemize}
            \item На основе границ интервала \texttt{x0} и \texttt{x1} формируется массив начальных точек \texttt{x}.
            \item Значения функции $f(x)$ вычисляются для всех точек, добавляются в массив \texttt{y}.
        \end{itemize}

        \item \textbf{Расчёт константы Липшица и функции оценки}:
        \begin{itemize}
            \item Для каждой пары соседних точек вычисляется приближённая константа Липшица.
            \item Сравнивается текущая оценка с максимальной найденной ранее. Если она превышает предыдущую, обновляются максимальная оценка $R$ и индекс интервала, в котором она достигается.
        \end{itemize}

        \item \textbf{Проверка критерия завершения}:
        \begin{itemize}
            \item Если текущая длина интервала меньше заданной точности $\varepsilon$, оптимизация завершается, и результатом становится значение $y$ в минимальной точке.
        \end{itemize}

        \item \textbf{Добавление новой точки}:
        \begin{itemize}
            \item Вычисляется новая точка внутри наиболее перспективного интервала, используя кусочно-линейную модель с учётом константы Липшица.
            \item Новая точка добавляется в массив \texttt{x}, массив упорядочивается.
        \end{itemize}
    \end{enumerate}

    \item \textbf{Постобработка результатов}:
    \begin{itemize}
        \item Результат минимизации (найденное значение функции) передаётся в выходной массив.
    \end{itemize}
\end{enumerate}

\subsection{Основные свойства алгоритма}
\begin{itemize}
    \item Алгоритм адаптивно уточняет интервал поиска, концентрируясь на областях с высокой потенциальной ценностью.
    \item Используется аппроксимация с константой Липшица для выбора перспективных областей.
    \item Гарантируется точность результата, соответствующая заданному параметру $\varepsilon$.
\end{itemize}


\section{Описание схемы распараллеливания}

\hspace*{1.25em}Схема распараллеливания алгоритма глобального поиска по методу Стронгина для одномерных задач оптимизации включает следующие этапы:

\begin{enumerate}
\item \textbf{Предобработка данных}: Процесс с рангом $0$ инициализирует начальные данные задачи, включая границы области поиска $[x_0, x_1]$ и точность $\varepsilon$. Затем он передает эти данные всем остальным процессам, обеспечивая синхронизацию начального состояния.
\item \textbf{Распределение интервалов}: Основной интервал $[x_0, x_1]$ делится на равные части, которые передаются другим процессам для вычисления локальных характеристик Липшица. Процесс с рангом $0$ управляет распределением, используя операцию \texttt{MPI\_Send} для передачи данных, и получает результаты вычислений с помощью \texttt{MPI\_Recv}.

\item \textbf{Вычисление характеристик Липшица}: Каждый процесс вычисляет локальные значения характеристик Липшица на своем интервале. Это включает вычисление разностей значений целевой функции $f(x)$ на концах подинтервалов и их деление на длину подинтервала.

\item \textbf{Сбор результатов}: Процесс с рангом $0$ собирает вычисленные характеристики Липшица от всех процессов, определяя максимальное значение $L_M$. Это значение используется для вычисления новой точки разбиения области поиска с учетом найденного максимального значения характеристики Липшица.

\item \textbf{Определение точки для следующего шага}: Основной процесс вычисляет критерий \textit{R} для всех интервалов, определяет интервал с максимальным значением \textit{R} и добавляет новую точку в этот интервал. Новая точка рассчитывается как среднее значение с учетом локальной характеристики Липшица на интервале.

\item \textbf{Проверка условия остановки}: Если длина выбранного интервала меньше $\varepsilon$, процесс завершает выполнение алгоритма. Всем процессам передается сигнал окончания работы с использованием MPI-тега.

\item \textbf{Завершение работы}: Процессы завершают вычисления, а процесс с рангом $0$ записывает результат оптимизации в выходные данные.
\end{enumerate}

\hspace*{1.25em}Таким образом, схема распараллеливания обеспечивает эффективное использование вычислительных ресурсов при решении задач глобальной оптимизации методом Стронгина.

\section{Результаты экспериментов}
\subsection{Параметры тестовой системы}
\begin{itemize}
    \item Операционная система: Windows 10
    \item Процессор: Intel(R) Core(TM) i5-10300H
    \item Объём оперативной памяти: 16 Gb
\end{itemize}
\newpage
\subsection{Таблица с данными тестирования}
\begin{table}[h!]
\begin{tabular}{cccc}
\toprule
\textbf{Количество процессов} & \textbf{Вид теста}         & \textbf{Время, мс} & \textbf{Ускорение} \\ 
\midrule
1                             & Pipeline                   & 0.299              & 1.00               \\ 
                              & Task                      & 0.325              & 1.00               \\ 
                              \cmidrule(lr){2-4}
                              & \textbf{Общее}            & 0.624              & 1.00               \\ 
\midrule
2                             & Pipeline                   & 0.260              & 1.15               \\ 
                              & Task                      & 0.270              & 1.20               \\ 
                              \cmidrule(lr){2-4}
                              & \textbf{Общее}            & 0.530              & 1.18               \\ 
\midrule
3                             & Pipeline                   & 0.383              & 0.78               \\ 
                              & Task                      & 0.402              & 0.81               \\ 
                              \cmidrule(lr){2-4}
                              & \textbf{Общее}            & 0.785              & 0.79               \\ 
\midrule
4                             & Pipeline                   & 0.373              & 0.80               \\ 
                              & Task                      & 0.398              & 0.82               \\ 
                              \cmidrule(lr){2-4}
                              & \textbf{Общее}            & 0.771              & 0.81               \\ 
\bottomrule
\end{tabular}
\caption{Результаты тестов производительности программы для алгоритма Стронгина.}
\label{table:performance}
\end{table}

\section{Выводы из результатов}

Из данных, представленных в Таблице~\ref{table:performance}, можно сделать несколько важных выводов о производительности параллельной реализации алгоритма Стронгина с использованием MPI.

Во-первых, наблюдается незначительное ускорение выполнения при переходе от 1 к 2 процессам. Например, общее время выполнения снижается с 0.624~мс для одного процесса до 0.530~мс для двух процессов, что соответствует ускорению в 1.18 раза. Это свидетельствует о том, что параллельная реализация начинает эффективно распределять задачи между процессами уже на начальном этапе.

Во-вторых, начиная с 3 процессов, ускорение становится менее выраженным и даже снижается. Например, при использовании 3 процессов общее время выполнения увеличивается до 0.785~мс, что соответствует ускорению лишь в 0.79 раза по сравнению с последовательной реализацией. При использовании 4 процессов наблюдается дальнейшее ухудшение, и ускорение составляет 0.81 раза. Этот эффект может быть связан с ростом накладных расходов на коммуникацию между процессами, что замедляет общую производительность.

Также стоит отметить, что наибольшее ускорение достигается при переходе от 1 к 2 процессам, когда эффективность распределения задач наиболее заметна. Однако при дальнейшем увеличении числа процессов производительность начинает снижаться, что указывает на наличие коммуникационных и организационных накладных расходов, доминирующих при большом числе процессов.

Таким образом, для оптимальной производительности параллельной реализации алгоритма Стронгина использование большого количества процессов нецелесообразно. Наиболее эффективно применять реализацию на 2 процессах, где достигается баланс между ускорением и накладными расходами на межпроцессное взаимодействие.

\section{Заключение}

В ходе выполнения данной работы была разработана и исследована параллельная реализация метода Стронгина с использованием технологии MPI. Основной целью было применение параллельных вычислений для оптимизации времени выполнения алгоритма при решении задач глобальной оптимизации. Реализация алгоритма позволила распределить вычисления между несколькими процессами, что особенно актуально для задач с высоким вычислительным требованием.

Для проверки корректности работы программы были проведены функциональные тесты, которые подтвердили правильность выполнения алгоритма в различных режимах. Также было проведено тестирование производительности параллельной реализации по сравнению с её последовательной версией. Эксперименты показали, что при использовании 2 процессов достигается наибольшее ускорение по сравнению с последовательной реализацией, что свидетельствует об эффективности распределения задач на этом этапе.

Однако при увеличении числа процессов ускорение постепенно снижается, что обусловлено увеличением накладных расходов на межпроцессное взаимодействие и синхронизацию. Это указывает на наличие ограничения по масштабируемости алгоритма при большом количестве процессов. Таким образом, для достижения оптимальной производительности важно учитывать баланс между количеством процессов и затратами на коммуникацию.

В итоге, поставленная задача была успешно решена: разработана параллельная версия метода Стронгина, проведён её анализ и получены выводы о производительности. Результаты экспериментов демонстрируют важность использования параллельных вычислений для ускорения выполнения алгоритмов глобальной оптимизации. Полученные данные могут быть использованы в дальнейшем для усовершенствования метода, а также для разработки других параллельных алгоритмов, применимых к задачам оптимизации.

\section{Литература}
\begin{enumerate}
    \item \href{https://ru.wikipedia.org/wiki/Метод_Стронгина}{Wikipedia. "Метод Стронгина"}.
    \item \href{https://www.youtube.com/watch?v=5OwpGndiB04}{YouTube unn-hpc-education. "Стронгин Р.Г. «Параллельные вычисления в глобальной оптимизации»"}.
    \item \href{https://github.com/knightvmk/Global-Optimization/blob/master/Strongin.pdf}{GitHub. "Р. Г. Стронгин, Параллельные вычисленияв задачах глобальной оптимизации. Монография"}.
    \item \href{https://parallel.ru/vvv/mpi.html#p1}{parralel.ru. "Технологии параллельного программирования. Message Passing Interface"}.
\end{enumerate}

\section{Приложения}
\addcontentsline{toc}{section}{Приложения}
\subsection*{Функция StronginSequential::run()}
\begin{lstlisting}[language=C++]
bool StronginSequential::run() {
  internal_order_test();
  std::vector<double> x;
  std::vector<double> y;
  double lipshM = 0.0;
  double lipshm = 0.0;
  double R = 0.0;
  size_t interval = 0;

  if (x1 > x0) {
    x.push_back(x0);
    x.push_back(x1);
  } else {
    x.push_back(x1);
    x.push_back(x0);
  }

  while (true) {
    for (size_t i = 0; i < x.size(); i++) {
      y.push_back(f(x[i]));
    }
    for (size_t i = 0; i < x.size() - 1; i++) {
      double lipsh = std::abs((y[i + 1] - y[i]) / (x[i + 1] - x[i]));
      if (lipsh > lipshM) {
        lipshM = lipsh;
        lipshm = lipsh + lipsh;
        double tempR = lipshm * (x[i + 1] - x[i]) + pow((y[i + 1] - y[i]), 2) / (lipshm * (x[i + 1] - x[i])) -
                       2 * (y[i + 1] + y[i]);
        if (tempR > R) {
          R = tempR;
          interval = i;
        }
      }
    }
    if (x[interval + 1] - x[interval] <= eps) {
      res = y[interval + 1];
      return true;
    }
    double newX;
    newX = (x[interval + 1] - x[interval]) / 2 + x[interval] + (y[interval + 1] - y[interval]) / (2 * lipshm);
    x.push_back(newX);
    sort(x.begin(), x.end());
    y.clear();
  }
}
\end{lstlisting}
\subsection*{Функция StronginParallel::run()}
\begin{lstlisting}[language=C++]
bool StronginParallel::run() {
  internal_order_test();

  int size;
  int rank;
  MPI_Status status;
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);

  double lipshM = 0;
  double lipshm = 0.0;
  double lipsh;

  int interval = 0;
  double R = 0.0;

  if (rank == 0) {
    std::vector<double> x;
    x.push_back(x0);
    x.push_back(x1);

    while (true) {
      sort(x.begin(), x.end());

      int part = static_cast<int>((x.size() - 1) / size);
      int remain = static_cast<int>((x.size() - 1) % size);

      if (part > 0) {
        for (int i = 1; i < size; ++i) {
          MPI_Send(x.data() + remain + (i - 1) * part, part, MPI_DOUBLE, i, 0, MPI_COMM_WORLD);
        }
      }
      for (int i = 0; i < part + remain; ++i) {
        lipsh = std::abs((f(x[i + 1]) - f(x[i])) / (x[i + 1] - x[i]));
        if (lipsh > lipshM) {
          lipshM = lipsh;
          lipshm = 2 * lipsh;
        }
      }
      if (part > 0) {
        for (int i = 1; i < size; i++) {
          MPI_Recv(&lipsh, 1, MPI_DOUBLE, i, MPI_ANY_TAG, MPI_COMM_WORLD, &status);
          if (lipsh > lipshM) {
            lipshM = lipsh;
            lipshm = 2 * lipsh;
          }
        }
      }

      double tempR;
      for (int i = 0; i < static_cast<int>(x.size()) - 1; i++) {
        tempR = lipshm * (x[i + 1] - x[i]) + pow((f(x[i + 1]) - f(x[i])), 2) / (lipshm * (x[i + 1] - x[i])) -
                2 * (f(x[i + 1]) + f(x[i]));
        if (tempR > R) {
          R = tempR;
          interval = i;
        }
      }
      if (x[interval + 1] - x[interval] <= eps) {
        for (int i = 1; i < size; ++i) MPI_Send(x.data(), 1, MPI_DOUBLE, i, 1, MPI_COMM_WORLD);
        res = x[interval + 1];
        MPI_Barrier(MPI_COMM_WORLD);
        return true;
      }

      double newX = (x[interval] + x[interval + 1]) / 2 - (f(x[interval + 1]) - f(x[interval])) / (lipshm + lipshm);
      x.push_back(newX);
    }
  } else {
    int part = 0;
    while (true) {
      MPI_Probe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);
      MPI_Get_count(&status, MPI_DOUBLE, &part);

      std::vector<double> x(part + 1);
      MPI_Recv(x.data(), part, MPI_DOUBLE, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);

      if (status.MPI_TAG == 1) {
        MPI_Barrier(MPI_COMM_WORLD);
        return true;
      }

      if (part != 0) {
        for (int i = 0; i < static_cast<int>(x.size()) - 1; ++i) {
          lipsh = (std::abs(f(x[i + 1]) - f(x[i]))) / (x[i + 1] - x[i]);
          if (lipsh > lipshM) {
            lipshM = lipsh;
            lipshm = lipshM + lipshM;
          }
        }
      }
      MPI_Send(&lipshm, 1, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD);
    }
  }
}
\end{lstlisting}
\end{document}
