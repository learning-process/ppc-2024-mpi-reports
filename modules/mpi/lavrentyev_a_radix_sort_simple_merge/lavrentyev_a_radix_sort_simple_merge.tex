\documentclass[12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}
\lstset{
	language=C++, 
	basicstyle=\ttfamily\small, 
	numbers=left, 
	numberstyle=\tiny, 
	stepnumber=1, 
	tabsize=4, 
	breaklines=true, 
	frame=single, 
	captionpos=b 
}

\begin{document}
	\begin{titlepage}
		\centering
		\large
		Министерство науки и высшего образования Российской Федерации\\[0.5cm]
		Федеральное государственное автономное образовательное учреждение высшего образования\\[0.5cm]
		\textbf{«Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»}\\
		(ННГУ)\\[1cm]
		Институт информационных технологий, математики и механики\\[0.5cm]
		Направление подготовки: \textbf{«Фундаментальная информатика и информационные технологии»}\\[1cm]
		
		\vfill
		{\LARGE \textbf{ОТЧЕТ}}\\[0.5cm]
		{\Large по задаче}\\[0.5cm]
		{\LARGE \textbf{«Поразрядная сортировка для вещественных чисел (тип double) с простым слиянием»}}\\[0.5cm]
		{\Large \textbf{Вариант №20}}\\[2.5cm]
		
		\hfill\parbox{0.5\textwidth}{
			\textbf{Выполнил:} \\
			студент группы 3822Б1ФИ3\_и1 \\
			\textbf{Лаврентьев Алексей}
		}\\[0.5cm]
		
		\hfill\parbox{0.5\textwidth}{
			\textbf{Преподаватель:} \\
			Сысоев А.В., доцент кафедры ВВСП
			
		}\\[2cm]
		
		Нижний Новгород\\
		2024
	\end{titlepage}
	
	\tableofcontents
	
	\newpage
	
	\section*{Введение}
	\addcontentsline{toc}{section}{Введение}
	
	\hspace*{1.25em}Задача сортировки данных является одной из фундаментальных в области вычислительных наук и играет важную роль в оптимизации различных процессов обработки данных. В условиях больших объемов информации, например, в научных вычислениях, обработке больших данных или в системах реального времени, необходимо использовать эффективные методы сортировки, способные работать с огромными массивами данных. Одним из таких методов является поразрядная сортировка (Radix Sort), которая используется для сортировки чисел, обрабатывая их поразрядно, начиная с младших разрядов.
	
	Вещественные числа, представленные типом \texttt{double}, часто встречаются в вычислениях, и их сортировка требует учёта специфики представления этих чисел в памяти, что делает задачу более сложной. В данной работе рассматривается параллельная версия поразрядной сортировки для вещественных чисел типа \texttt{double} с использованием простого слияния. Параллельная реализация данного алгоритма позволяет значительно ускорить процесс сортировки, распределяя данные между несколькими процессами и выполняя локальную сортировку на каждом из них.
	
	Алгоритм, описанный в данной работе, включает несколько ключевых этапов: распределение данных между процессами, локальная поразрядная сортировка, слияние отсортированных частей данных и сбор результатов на главном процессе. Для распараллеливания используется библиотека MPI (Message Passing Interface), которая позволяет эффективно организовать взаимодействие между процессами и распределение данных.
	
	Целью данной работы является разработка и анализ параллельной реализации поразрядной сортировки для массива вещественных чисел с применением простого слияния, а также оценка её эффективности по сравнению с последовательной версией алгоритма.
	
	\newpage
	
	\section*{Постановка задачи} \addcontentsline{toc}{section}{Постановка задачи}
	
	\hspace*{1.25em}Целью данной работы является разработка и исследование алгоритма параллельной поразрядной сортировки для массива вещественных чисел типа \texttt{double}, с использованием простого слияния. Особое внимание уделяется параллельной реализации, которая использует библиотеку MPI для распределения вычислений между процессами, что позволяет значительно повысить производительность сортировки больших массивов данных.
	
	Для достижения поставленной цели необходимо решить следующие задачи: \begin{itemize} 
		\item Реализовать последовательную версию поразрядной сортировки для вещественных чисел типа \texttt{double}, учитывая особенности представления этих чисел в памяти. 
		\item Разработать параллельную версию алгоритма, использующую возможности библиотеки MPI для эффективного распределения данных и выполнения локальной сортировки на каждом процессе. 
		\item Произвести сбор отсортированных данных и слияние локальных результатов с использованием метода простого слияния. 
		\item Сравнить производительность последовательной и параллельной версий алгоритма на различных объёмах данных, а также проанализировать влияние числа процессов на скорость сортировки. 
		\item Провести функциональное тестирование для обеих версий алгоритма, чтобы удостовериться в их корректности и соответствии результатов. 
		\item Подготовить отчёт, в котором будут представлены этапы разработки, результаты экспериментов и выводы по эффективности параллельного подхода. \end{itemize}
	
	\newpage
	
	\section*{Описание алгоритма} \addcontentsline{toc}{section}{Описание алгоритма}
	
	\hspace*{1.25em}Алгоритм поразрядной сортировки для массива вещественных чисел типа \texttt{double} работает следующим образом:
	
	\subsection*{Основной алгоритм поразрядной сортировки} Алгоритм поразрядной сортировки (или радикальная сортировка) обрабатывает числа по разрядам, начиная с наименее значимого. В случае с числами с плавающей точкой, представление которых состоит из знака, экспоненты и мантиссы, сортировка происходит по отдельным частям этих представлений. Каждый разряд рассматривается как отдельное число, которое можно отсортировать стандартными методами.
	
	Процесс сортировки состоит из следующих шагов: \begin{itemize} \item \textbf{Приведение чисел к целому виду.} Вначале все вещественные числа преобразуются в целые, учитывая порядок и точность, что позволяет проводить сортировку по разрядам. Преобразование проводится с учётом экспоненты и мантиссы. \item \textbf{Сортировка по разряду.} Сортировка происходит по очередному разряду всех чисел. Это можно реализовать с использованием алгоритма подсчётной сортировки, так как разряды чисел ограничены. \item \textbf{Повторение для всех разрядов.} Сортировка повторяется для каждого разряда, начиная с наименее значимого (младшего) до самого значимого (старшего). \end{itemize}
	
	Для эффективной сортировки на каждом этапе используется алгоритм сортировки подсчётом, который позволяет работать с большими массивами чисел за время, пропорциональное количеству чисел и диапазону значений разряда.
	
	\subsection*{Параллельная версия алгоритма} Для ускорения работы алгоритма была разработана параллельная версия с использованием библиотеки MPI (Message Passing Interface). Параллельный алгоритм распределяет данные на несколько процессов, каждый из которых выполняет сортировку части массива. После того как локальные массивы отсортированы, происходит процесс слияния данных для получения отсортированного массива.
	
	Процесс параллельной сортировки включает следующие этапы: \begin{itemize} \item \textbf{Разбиение данных на части.} Исходный массив делится на несколько частей, которые распределяются между процессами. \item \textbf{Локальная сортировка.} Каждый процесс выполняет сортировку своей части данных по разряду. \item \textbf{Слияние отсортированных частей.} После того как все процессы закончат локальную сортировку, начинается слияние отсортированных данных. Это требует обмена данными между процессами, для чего используется MPI. \end{itemize}
	
	Слияние данных выполняется путём обмена локальными отсортированными массивами между процессами, что позволяет эффективно получить окончательно отсортированный массив.
	
	\subsection*{Применение алгоритма} Этот алгоритм используется для сортировки больших массивов вещественных чисел. Он может быть полезен в таких областях, как обработка больших данных, научные вычисления, машинное обучение и другие, где требуется эффективная сортировка больших наборов данных с использованием параллельных вычислений. В частности, параллельная версия алгоритма значительно ускоряет процесс сортировки за счёт распределения вычислений между несколькими процессами, что особенно важно для обработки массивов размером в несколько гигабайт или терабайт.
	
	\newpage
	
	\section*{Описание схемы распараллеливания}
	\addcontentsline{toc}{section}{Описание схемы распараллеливания}
	
	\hspace*{1.25em}Схема распараллеливания алгоритма поразрядной сортировки для вещественных чисел с использованием простого слияния основана на следующих этапах:
	\begin{enumerate}
		\item \textbf{Распределение данных}: исходный массив делится на несколько подмассивов, которые распределяются между процессами с помощью операции Scatterv.
		\begin{itemize}
			\item Каждый процесс получает свой подмассив, который является частью исходного массива данных.
			\item Размеры подмассивов и их распределение зависят от общего числа процессов и размера исходного массива.
		\end{itemize}
		
		\item \textbf{Локальная поразрядная сортировка}: каждый процесс выполняет поразрядную сортировку на своем подмассиве.
		\begin{itemize}
			\item Для каждой части массива используется алгоритм поразрядной сортировки (radix sort), выполняющий сортировку данных на уровне отдельных разрядов.
			\item Каждый процесс работает только с локальными данными, что позволяет распараллелить сортировку.
		\end{itemize}
		
		\item \textbf{Сбор данных}: отсортированные подмассивы собираются на нулевом процессе с помощью операции Gatherv.
		\begin{itemize}
			\item Каждый процесс отправляет свой отсортированный подмассив на главный процесс.
			\item Главный процесс собирает все локально отсортированные части в один массив.
		\end{itemize}
		
		\item \textbf{Слияние отсортированных данных}: на нулевом процессе выполняется слияние отсортированных подмассивов в итоговый отсортированный массив.
		\begin{itemize}
			\item Для слияния используется приоритетная очередь (min-heap), которая последовательно извлекает минимальные элементы из каждого подмассива и добавляет их в итоговый массив.
			\item Слияние позволяет создать окончательно отсортированный массив, объединив все локальные результаты.
		\end{itemize}
		
		\item \textbf{Возврат результата}: после завершения слияния итоговый отсортированный массив передается на выход.
		\begin{itemize}
			\item Главный процесс передает отсортированный массив обратно в основной поток программы.
			\item Результат сортировки доступен для дальнейшего использования или обработки.
		\end{itemize}
	\end{enumerate}
	
	\newpage
	
	\section*{Программная реализация}
	
	\hspace*{1.25em}В MPI-версии поразрядной сортировки с простым слиянием для вещественных чисел основная идея заключается в эффективном распределении данных между процессами и использовании параллельных вычислений для ускорения процесса сортировки. Алгоритм выполняет локальную сортировку на каждом процессе, а затем собирает и сливает отсортированные части массива на главном процессе. Этапы MPI-версии алгоритма:
	
	\subsubsection*{Pre-processing}
	\begin{itemize}
		\item На корневом процессе загружается массив данных, который должен быть отсортирован.
		\item Массив данных распределяется между процессами с помощью операции \texttt{MPI\_Scatterv}, чтобы каждый процесс получил часть массива.
		\item Для каждого процесса рассчитываются размеры подмассивов и их распределение, чтобы обеспечить равномерное разделение данных.
	\end{itemize}
	
	\subsubsection*{Validation}
	\begin{itemize}
		\item На корневом процессе выполняется проверка корректности входных данных:
		\begin{itemize}
			\item Размер массива должен быть больше нуля.
			\item Буферы для данных и выходных результатов должны быть правильно инициализированы.
		\end{itemize}
	\end{itemize}
	
	\subsubsection*{Run}
	
	\begin{enumerate}
		\item \textbf{Распределение данных}:
		\begin{itemize}
			\item Исходный массив разделяется на блоки, которые распределяются между процессами с использованием операции \texttt{MPI\_Scatterv}.
			\item Каждый процесс получает свой подмассив для локальной сортировки.
		\end{itemize}
		
		\item \textbf{Локальная поразрядная сортировка}:
		\begin{itemize}
			\item Каждый процесс выполняет поразрядную сортировку на своем подмассиве с использованием функции \texttt{radixSortDouble}.
			\item Сортировка выполняется поразрядно для каждого числа, начиная с младших разрядов и до старших.
		\end{itemize}
		
		\item \textbf{Сбор отсортированных данных}:
		\begin{itemize}
			\item После сортировки локальных подмассивов каждый процесс отправляет свои отсортированные данные на корневой процесс с помощью операции \texttt{MPI\_Gatherv}.
			\item На корневом процессе выполняется слияние отсортированных подмассивов с помощью функции \texttt{mergeSortedVectorsInPlace}, которая использует приоритетную очередь для эффективного слияния.
		\end{itemize}
		
		\item \textbf{Слияние отсортированных данных}:
		\begin{itemize}
			\item Слияние данных осуществляется на корневом процессе с использованием алгоритма слияния с приоритетной очередью (min-heap).
			\item После слияния формируется итоговый отсортированный массив, который будет передан в выходной буфер.
		\end{itemize}
	\end{enumerate}
	
	\subsubsection*{Post-processing}
	\begin{itemize}
		\item На корневом процессе финальный отсортированный массив копируется в выходной буфер, который используется для сохранения результата сортировки.
	\end{itemize}
	
	\subsubsection*{Ключевые особенности реализации}
	\begin{itemize}
		\item Использование параллельной сортировки с локальной поразрядной сортировкой на каждом процессе позволяет значительно ускорить обработку больших массивов данных.
		\item Применение операций \texttt{MPI\_Scatterv} и \texttt{MPI\_Gatherv} для распределения и сбора данных между процессами эффективно организует работу с большими объемами данных.
		\item Алгоритм слияния с приоритетной очередью минимизирует накладные расходы на слияние отсортированных частей массива.
		\item Технология слияния позволяет эффективно работать с отсортированными блоками и гарантировать правильность итоговой сортировки.
	\end{itemize}
	
	\newpage
	
	\section*{Результаты экспериментов}
	
	\hspace*{1.25em}Для оценки производительности алгоритма поразрядной сортировки с простым слиянием были проведены измерения времени выполнения последовательной реализации и параллельной реализации с использованием MPI. В таблице ниже представлены результаты тестирования для различных количеств процессов. Размер входных данных равен 1000000 элементов.
	
	\begin{table}[htbp]
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Количество процессов} & \textbf{Вид теста} & \textbf{Время (сек)} \\ \hline
			1 & task\_run & 0.717 \\ \hline
			1 & pipeline\_run & 0.732 \\ \hline
			2 & task\_run & 0.594 \\ \hline
			2 & pipeline\_run & 0.603 \\ \hline
			3 & task\_run & 0.485 \\ \hline
			3 & pipeline\_run & 0.505 \\ \hline
			4 & task\_run & 0.487 \\ \hline
			4 & pipeline\_run & 0.508 \\ \hline
			6 & task\_run & 0.495 \\ \hline
			6 & pipeline\_run & 0.510 \\ \hline
			12 & task\_run & 0.489 \\ \hline
			12 & parallel\_run & 0.498 \\ \hline
		\end{tabular}
		\label{tab:performance_results}
	\end{table}
	
	\newpage
	
	\section*{Выводы из результатов}
	
	\hspace*{1.25em}Как видно из Таблицы, параллельная реализация алгоритма поразрядной сортировки с простым слиянием демонстрирует улучшение времени выполнения по сравнению с последовательной версией. Размеры входных данных были выбраны такими, чтобы обеспечить эффективное использование вычислительных ресурсов и продемонстрировать влияние параллелизма на производительность.
	
	Наибольшее улучшение наблюдается при увеличении количества процессов, что связано с более эффективным распределением данных и вычислений между процессами. Однако при увеличении числа процессов до 12 скорость обработки данных становится стабильно высокой, и дальнейшее увеличение числа процессов не приводит к значительному ускорению. Это можно объяснить увеличением накладных расходов на синхронизацию и обмен данными между процессами, что ограничивает возможное улучшение производительности.
	
	Эксперименты проводились на следующей системе: \begin{itemize} \item Операционная система: Windows 11. \item Процессор: AMD Ryzen 5 5500 2.1GHz, 6 ядер. \item Оперативная память: 16 ГБ. \end{itemize}
	
	\newpage
	
	\section*{Заключение}
	\addcontentsline{toc}{section}{Заключение}
	
	\hspace*{1.25em}В ходе данной работы была разработана и исследована параллельная версия алгоритма поразрядной сортировки для массива вещественных чисел типа \texttt{double} с использованием простого слияния. Реализация алгоритма включала как последовательный, так и параллельный подход с применением библиотеки MPI для эффективного распределения данных и выполнения локальной сортировки.
	
	Результаты экспериментов показали значительное улучшение времени выполнения параллельной версии алгоритма по сравнению с последовательной реализацией, особенно при увеличении числа процессов. Однако увеличение количества процессов до определенного уровня не приводит к пропорциональному ускорению из-за накладных расходов на обмен данными между процессами. Это подчеркивает важность оптимизации распределения и синхронизации данных для дальнейшего улучшения производительности.
	
	Проведенное тестирование подтвердило корректность работы обеих версий алгоритма. Таким образом, задача была успешно решена: разработан и протестирован параллельный алгоритм поразрядной сортировки для вещественных чисел, а также проведен анализ его производительности. Полученные результаты подтверждают эффективность использования параллельных вычислений для сортировки больших массивов данных, что особенно важно в области обработки больших данных и научных вычислений.
	
	\newpage
	
	\section*{Литература}
	\addcontentsline{toc}{section}{Литература}
	
	\begin{enumerate}
		\item \href{https://en.wikipedia.org/wiki/Radix_sort}{Wikipedia. Статья "Radix sort"}.
		\item \href{https://www.geeksforgeeks.org/radix-sort/}{Статья "Radix Sort – Data Structures and Algorithms Tutorials"}.
	\end{enumerate}
	
	\appendix
	\newpage
	\section*{Приложение}
	\addcontentsline{toc}{section}{Приложение}
	
	В данном разделе представлены реализации классов параллельной и последовательной версий оразрядной сортировки для вещественных чисел (тип double) с простым слиянием.
	
	
	\subsection*{\texttt{ops\_mpi.hpp}}
	
	\begin{lstlisting}[language=C++]
		#pragma once
		
		#include <gtest/gtest.h>
		
		#include <boost/mpi/collectives.hpp>
		#include <boost/mpi/communicator.hpp>
		
		#include "core/task/include/task.hpp"
		
		namespace lavrentyev_a_radix_sort_simple_merge_mpi {
			
			struct Node {
				double value;
				int source_rank;
				
				bool operator>(const Node& other) const { return value > other.value; }
			};
			
			void mergeSortedVectorsInPlace(std::vector<double>& arr, const std::vector<int>& sizes, const std::vector<int>& displs);
			
			template <typename RandomIt>
			void radixSortDouble(RandomIt begin, RandomIt end) {
				if (begin == end) return;
				
				using ValueType = typename std::iterator_traits<RandomIt>::value_type;
				static_assert(std::is_floating_point_v<ValueType>, "This function is designed for floating-point types.");
				
				const size_t numBits = sizeof(ValueType) * 8;
				const size_t numBuckets = 256;
				
				union DoubleIntUnion {
					ValueType d;
					uint64_t u;
				};
				
				std::vector<ValueType> buffer(std::distance(begin, end));
				std::vector<size_t> count(numBuckets);
				
				for (size_t byte = 0; byte < sizeof(ValueType); ++byte) {
					std::fill(count.begin(), count.end(), 0);
					
					for (auto it = begin; it != end; ++it) {
						DoubleIntUnion di;
						di.d = *it;
						uint64_t value = di.u;
						if (value & (1ULL << (numBits - 1))) {
							value = ~value;
						} else {
							value |= (1ULL << (numBits - 1));
						}
						uint8_t byteValue = (value >> (byte * 8)) & 0xFF;
						++count[byteValue];
					}
					
					for (size_t i = 1; i < numBuckets; ++i) {
						count[i] += count[i - 1];
					}
					
					for (auto it = end; it != begin;) {
						--it;
						DoubleIntUnion di;
						di.d = *it;
						uint64_t value = di.u;
						if (value & (1ULL << (numBits - 1))) {
							value = ~value;
						} else {
							value |= (1ULL << (numBits - 1));
						}
						uint8_t byteValue = (value >> (byte * 8)) & 0xFF;
						buffer[--count[byteValue]] = *it;
					}
					
					std::copy(buffer.begin(), buffer.end(), begin);
				}
			}
			
			class RadixSimpleMerge : public ppc::core::Task {
				public:
				explicit RadixSimpleMerge(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
				bool pre_processing() override;
				bool validation() override;
				bool run() override;
				bool post_processing() override;
				
				private:
				int wsize;
				int wrank;
				int vsize;
				std::vector<double> arr;
				std::vector<int> sizes;
				std::vector<int> displs;
				std::vector<double> local_arr;
				boost::mpi::communicator world;
			};
			
		}  // namespace lavrentyev_a_radix_sort_simple_merge_mpi
	\end{lstlisting}
	
	\subsection*{\texttt{ops\_mpi.cpp}}
	
	\begin{lstlisting}[language=C++]
		#include "mpi/lavrentyev_a_radix_sort_simple_merge/include/ops_mpi.hpp"
		
		#include <algorithm>
		#include <boost/serialization/array.hpp>
		#include <boost/serialization/vector.hpp>
		#include <queue>
		#include <vector>
		
		void lavrentyev_a_radix_sort_simple_merge_mpi::mergeSortedVectorsInPlace(std::vector<double>& arr, const std::vector<int>& sizes,
		const std::vector<int>& displs) {
			std::vector<double> result;
			using Element = std::pair<double, std::pair<int, int>>;
			std::priority_queue<Element, std::vector<Element>, std::greater<>> min_heap;
			
			for (size_t i = 0; i < sizes.size(); ++i) {
				if (sizes[i] > 0) {
					min_heap.push({arr[displs[i]], {static_cast<int>(i), 0}});
				}
			}
			
			while (!min_heap.empty()) {
				auto [value, indices] = min_heap.top();
				min_heap.pop();
				
				result.push_back(value);
				
				int vec_index = indices.first;
				int elem_index = indices.second;
				
				if (elem_index + 1 < sizes[vec_index]) {
					min_heap.push({arr[displs[vec_index] + elem_index + 1], {vec_index, elem_index + 1}});
				}
			}
			
			arr = std::move(result);
		}
		
		bool lavrentyev_a_radix_sort_simple_merge_mpi::RadixSimpleMerge::validation() {
			internal_order_test();
			
			if (world.rank() != 0) return true;
			
			return taskData->inputs_count[0] > 1;
		}
		
		bool lavrentyev_a_radix_sort_simple_merge_mpi::RadixSimpleMerge::pre_processing() {
			internal_order_test();
			
			wsize = world.size();
			wrank = world.rank();
			
			vsize = taskData->inputs_count[0];
			
			if (world.rank() == 0) {
				auto* vec_data = reinterpret_cast<double*>(taskData->inputs[0]);
				
				arr.assign(vec_data, vec_data + vsize);
			}
			
			sizes.resize(wsize, 0);
			displs.resize(wsize, 0);
			
			for (int i = 0; i < wsize; i++) {
				sizes[i] = vsize / wsize + (i < vsize % wsize ? 1 : 0);
				displs[i] = (i == 0) ? 0 : displs[i - 1] + sizes[i - 1];
			}
			
			local_arr.resize(sizes[wrank]);
			
			return true;
		}
		
		bool lavrentyev_a_radix_sort_simple_merge_mpi::RadixSimpleMerge::run() {
			internal_order_test();
			
			boost::mpi::scatterv(world, arr.data(), sizes, displs, local_arr.data(), sizes[wrank], 0);
			
			radixSortDouble(local_arr.begin(), local_arr.end());
			
			if (wrank == 0) arr.clear();
			boost::mpi::gatherv(world, local_arr.data(), local_arr.size(), arr.data(), sizes, displs, 0);
			if (wrank == 0) mergeSortedVectorsInPlace(arr, sizes, displs);
			
			return true;
		}
		
		bool lavrentyev_a_radix_sort_simple_merge_mpi::RadixSimpleMerge::post_processing() {
			internal_order_test();
			
			if (world.rank() == 0) {
				auto* out_vector_ = reinterpret_cast<double*>(taskData->outputs[0]);
				std::copy(arr.begin(), arr.end(), out_vector_);
			}
			
			return true;
		}
	\end{lstlisting}
	
	\subsection*{\texttt{ops\_seq.hpp}}
	
	\begin{lstlisting}[language=C++]
		#pragma once
		
		#include <gtest/gtest.h>
		
		#include <memory>
		#include <vector>
		
		#include "core/task/include/task.hpp"
		
		namespace lavrentyev_a_radix_sort_simple_merge_seq {
			
			template <typename RandomIt>
			void radixSortDouble(RandomIt begin, RandomIt end) {
				if (begin == end) return;
				
				using ValueType = typename std::iterator_traits<RandomIt>::value_type;
				static_assert(std::is_floating_point_v<ValueType>, "This function is designed for floating-point types.");
				
				const size_t numBits = sizeof(ValueType) * 8;
				const size_t numBuckets = 256;
				
				union DoubleIntUnion {
					ValueType d;
					uint64_t u;
				};
				
				std::vector<ValueType> buffer(std::distance(begin, end));
				std::vector<size_t> count(numBuckets);
				
				for (size_t byte = 0; byte < sizeof(ValueType); ++byte) {
					std::fill(count.begin(), count.end(), 0);
					
					for (auto it = begin; it != end; ++it) {
						DoubleIntUnion di;
						di.d = *it;
						uint64_t value = di.u;
						if (value & (1ULL << (numBits - 1))) {
							value = ~value;
						} else {
							value |= (1ULL << (numBits - 1));
						}
						uint8_t byteValue = (value >> (byte * 8)) & 0xFF;
						++count[byteValue];
					}
					
					for (size_t i = 1; i < numBuckets; ++i) {
						count[i] += count[i - 1];
					}
					
					for (auto it = end; it != begin;) {
						--it;
						DoubleIntUnion di;
						di.d = *it;
						uint64_t value = di.u;
						if (value & (1ULL << (numBits - 1))) {
							value = ~value;
						} else {
							value |= (1ULL << (numBits - 1));
						}
						uint8_t byteValue = (value >> (byte * 8)) & 0xFF;
						buffer[--count[byteValue]] = *it;
					}
					
					std::copy(buffer.begin(), buffer.end(), begin);
				}
			}
			
			class RadixSimpleMerge : public ppc::core::Task {
				public:
				explicit RadixSimpleMerge(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
				bool pre_processing() override;
				bool validation() override;
				bool run() override;
				bool post_processing() override;
				
				private:
				std::vector<double> arr;
				int vsize;
			};
			
		}  // namespace lavrentyev_a_radix_sort_simple_merge_seq
	\end{lstlisting}
	
	\subsection*{\texttt{ops\_seq.cpp}}
	
	\begin{lstlisting}[language=C++]
		#include "seq/lavrentyev_a_radix_sort_simple_merge/include/ops_seq.hpp"
		
		#include <algorithm>
		
		namespace lavrentyev_a_radix_sort_simple_merge_seq {
			
			bool RadixSimpleMerge::validation() {
				internal_order_test();
				
				return taskData->inputs_count[0] > 1;
			}
			
			bool RadixSimpleMerge::pre_processing() {
				internal_order_test();
				
				auto* vec_data = reinterpret_cast<double*>(taskData->inputs[0]);
				vsize = taskData->inputs_count[0];
				
				arr.assign(vec_data, vec_data + vsize);
				
				return true;
			}
			
			bool RadixSimpleMerge::run() {
				internal_order_test();
				
				radixSortDouble(arr.begin(), arr.end());
				
				return true;
			}
			
			bool RadixSimpleMerge::post_processing() {
				internal_order_test();
				
				auto* out_vector_ = reinterpret_cast<double*>(taskData->outputs[0]);
				std::copy(arr.begin(), arr.end(), out_vector_);
				
				return true;
			}
			
		}  // namespace lavrentyev_a_radix_sort_simple_merge_seq
	\end{lstlisting}
	
\end{document}