\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{indentfirst}
\usepackage{float}
\usepackage{geometry}
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}

\title{Отчёт. Задача 3. Вариант 12. Многошаговая схема решения двумерных задач глобальной оптимизации. Распараллеливание путём разделения области поиска.}
\author{Автор: Ворошилов Виталий 3822Б1ПР1}
\date{27.12.2024}

\begin{document}

\maketitle
Преподаватель: доцент кафедры ВВСП ИИТММ, кандидат технических наук Александр Владимирович Сысоев
\newpage

\tableofcontents
\newpage

\section{Введение}

В задаче оптимизации обычно предполагается наличие некоторой математической модели, которая принимает набор параметров и имеет набор характеристик, которые от этих параметров зависят.

Задача оптимизации заключается в подборе такой комбинации параметров, при которой характеристики будут наилучшими для данной задачи. А задачи могут быть различные - требование оптимизировать некоторую математическую модель возникает в различных сферах человеческой деятельности, так как множество реальных задач можно свести к задаче оптимизации.
       
\section{Постановка задачи}

Достаточно общая в своей формулировке задача оптимизации была проинтерпретирована следующим образом:
\begin{itemize}
    \item набор переменных (параметров) системы - \textit{(x, y)}, \textit{x} и \textit{y} представляют собой числа с плавающей точкой;
    \item набор характеристик системы - это некоторое количество функций \textit{$g_1(x, y), g_2(x, y), ..., g_n(x, y)$};
    \item одна из функций - критерий, её значение будет минимизироваться: \textit{$q(x, y) \rightarrow min$};
    \item остальные функции - ограничения, их значения должны быть \textit{$\leq 0$}.
\end{itemize}

Соотвественно задача заключалась в написании последоваельной программы и параллельной программы (с использованием библиотеки MPI), позволяющих найти минимум заданной функции-критерия $q(x, y)$ при условии что все заданные функции-ограничения неположительны: \textit{$g_1(x, y) \leq 0, g_2(x, y) \leq 0, ..., g_n(x, y) \leq 0$}.

Кроме того, необходимо было написать функциональные тесты обеих версий программ и проверить работоспособность кода.

\section{Описание алгоритма}
Алгоритм программы можно описать следующим образом:
\begin{enumerate}
    \item в исследуемой области формируется сетка точек \textit{$(x, y)$} на основе величины шага, которая постоянна и задаётся для x и для y отдельно);
    \item в каждой точке сетки высчитывается значение минимизируемой функции-критерия \textit{$q(x, y)$}, а также проверяется выполнение неравенств-ограничений \textit{$g_1(x, y), g_2(x, y), ..., g_n(x, y)$};
    \item если точка \textit{$(x_i, y_i)$} подходит под все ограничения и её значение меньше чем значения всех предыдущих подходящих, точка объявляется минимумом;
    \item проверив все точки сетки, получаем приближение минимума функции в заданной области при заданных ограничениях.
\end{enumerate}



\section{Описание схемы распараллеливания}
Параллельная версия программы реализована с помощью библиотеки MPI, которая предполагает что выполнение программы происходит несколькими процессами, которые не имеют общей памяти и могут обмениватся данными только посредством специальных операций отправки. Поэтому для работы программы необходимо наладить правильное взаимодействие процессов и передачу данных между ними.

Общая идея взаимодействия такова: главный процесс формирует сетку из точек по заданному шагу, упаковывает её в виде вектора и рассылает каждому процессу подвектор из этого вектора. Разделение происходит просто с помощью деления общего числа точек на количество процессов, целая часть от деления даётся точно каждому процессу а остаток от деления распределяется начиная с первого в списке процесса по одному элементу пока сам остаток не закончится). Далее каждый процесс работает со своим подвектором, и затем результат снова будет формироваться на главном процессе.



\section{Описание MPI-версии}
MPI-версия программы реализована на языке программирования \textit{C++} с помощью функций библиотеки \textit{boost::mpi}.

Алгоритм работы параллельной MPI-программы можно описать следующим образом:
\begin{enumerate}
    \item процесс \textit{0} в исследуемой области формируе сетку точек \textit{$(x, y)$} на основе величины шага, которая постоянна и задаётся для \textit{x} и для \textit{y} отдельно), и сохраняет эту сетку в виде вектора;
    \item вектор разделяется на подвекторы по выше описанной схеме и каждому процессу отправляется свой подвектор с помощью функции \textit{boost::mpi::scatterv()};
    \item процессы по отдельности в каждой точке сетки высчитывают значение минимизируемой функции-критерия \textit{$q(x, y)$}, а также проверяют выполнение неравенств-ограничений \textit{$g_1(x, y), g_2(x, y), ..., g_n(x, y)$};
    \item если точка \textit{$(x_i, y_i)$} подходит под все ограничения и её значение меньше чем значения всех предыдущих подходящих, точка объявляется локальным минимумом для подвектора с которым работает процесс;
    \item проверив все точки своего подвектора, процесс получил локальный минимум;
    \item с помощью функции \textit{boost::mpi::gather()} все процессы отправляют свои локальные минимумы процессу \textit{0}, который формирует вектор локальных минимумов;
    \item процесс \textit{0} находит минимум этого вектора локальных минимумов - глобальный минимум.
\end{enumerate}

\section{Результаты экспериментов}
\subsection{Алгоритм тестирования}
Для проверки работоспособности программы были написаны функциональные тесты, которые выполняют следующие действия:
\begin{enumerate}
    \item формирование набора входных данных (строка функции критерия \textit{$q(x, y)$} и её длина, целое число представляющее собой количество функций-ограничений \textit{$g_i(x, y)$} в задаче и их длины, границы области поиска (границы по \textit{x} и по \textit{y}), количество шагов сетки (по \textit{x} и по \textit{y});
    \item запуск программы на этом наборе входных данных;
    \item проверка выходных данных - координат \textit{$(x, y)$} точки глобального минимума и значения функии-критерия \textit{$q(x, y)$} в 
    этой точке - минимальное значение;
\end{enumerate}

Т.к. схема поиска не даёт точного решения (потому что из всей области берётся лишь ограниченное число точек), проверка выходных данных осуществлялась с некоторым допустимым отклонением \textit{eps}.

Входные данные задавались вручную, чтобы была возможность проверить правильность выходных данных.

\subsection{Условия тестирования}
Для тестирования использовалась система:
\begin{itemize}
    \item Операционная система Windows 10 64-bit;
    \item Процессор AMD Ryzen 5 5600, 6 ядер 3.5 ГГц;
    \item Оперативная память 24 ГБ
\end{itemize}

Для тестирования использовался следующий набор входных данных:
\begin{itemize}
    \item функция-критерий: $q(x, y) = x^2 +y^2$;
    \item ограничение 1: $g_1(x, y) = -x + 1 \leq 0$;
    \item ограничение 2: $g_2(x, y) = -y + 1 \leq 0$;
    \item область поиска по \textit{x}: $-5.0 \leq x \leq 5.0$;
    \item область поиска по \textit{y}: $-5.0 \leq y \leq 5.0$;
    \item количество шагов сетки по \textit{x}: 5000;
    \item количество шагов сетки по \textit{x}: 5000
\end{itemize}

\subsection{Результаты}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Количество процессов} & \textbf{\textit{pipeline run, сек}} & \textbf{\textit{task run, сек}} \\
\hline
1                             & 2.6663                             & 2.6783                           \\
2                             & 2.3775                             & 2.3991                           \\
3                             & 2.2285                             & 2.2537                           \\
4                             & 2.0865                             & 2.0795                           \\
5                             & 1.9900                             & 2.0249                           \\
\hline
\end{tabular}
\caption{Результаты тестирования на разных количествах процессов}
\end{table}

\section{Вывод из результатов}
Исходя из результатов тестирования видно, что по мере увеличения количества процессов, выполняющих программу, время выполнения уменьшается в пределах 15\% разницы. Значит, схема распараллеливания работает, но, вероятно, при более детальном подходе к её реализации можно добиться большего ускорения.

Также необходимо отметить, что для тестирования была взята довольно простая функция и простые ограничения, так что сами расчёты занимали не столь много времени сколько занимали операции обмена данными между процессами.

\section{Заключение}
В ходе работы реализованы последоваельная и параллельная программы (с использованием библиотеки MPI), позволяющие получить приближённое решение задачи глобальной оптимизации - найти минимум заданной функции-критерия $q(x, y)$ при условии что все заданные функции-ограничения \textit{$g_1(x, y), g_2(x, y), ..., g_n(x, y)$} неположительны.

Параллельная реализация дала ускорение в 39\% при запуске на 5 процессах, что довольно значительно, но, возможно, это не предел, так как задача тестировалась на не совсем подходящих для параллельных вычислений входных данных. Очень вероятно что при подходящих данных (более сложных функциях, требующих серьёзных вычислений) ускорение будет значительнее.

Но в целом ускорение получено, точность решения не утеряна и можно утверждать что схема распараллеливания для данной задачи реализована успешно.

\section{Литература}
\begin{itemize}
    \item д.ф.-м.н. Стронгин Р.Г., ННГУ, Лекция «Параллельные вычисления в глобальной оптимизации»
\end{itemize}

\section{Приложения}
\subsection{Код функции run() параллельной программы}
\begin{verbatim}
bool voroshilov_v_bivariate_optimization_by_area_mpi::OptimizationMPITaskParallel::run() {
  internal_order_test();

  std::vector<Point> points;

  if (world.rank() == 0) {
    // Preparing vector of points:

    double x_step = (x_area.max_value - x_area.min_value) / x_area.steps_count;
    double y_step = (y_area.max_value - y_area.min_value) / y_area.steps_count;

    Point current_point(x_area.min_value, y_area.min_value);

    while (current_point.y <= y_area.max_value) {
      while (current_point.x <= x_area.max_value) {
        points.push_back(current_point);
        current_point.x += x_step;
      }
      current_point.x = x_area.min_value;
      current_point.y += y_step;
    }
  }

  // Vector distribution:
  int part;
  int remainder;
  if (world.rank() == 0) {
    part = points.size() / world.size();
    remainder = points.size() % world.size();
  }
  boost::mpi::broadcast(world, part, 0);
  boost::mpi::broadcast(world, remainder, 0);

  std::vector<int> parts(world.size(), part);
  std::vector<int> offsets(world.size());

  for (int i = 0; i < world.size(); i++) {
    if (remainder > 0) {
      parts[i]++;
      remainder--;
    }
    if (i == 0) {
      offsets[i] = 0;
    } else {
      offsets[i] = offsets[i - 1] + parts[i - 1];
    }
  }

  std::vector<Point> local_points(parts[world.rank()]);
  boost::mpi::scatterv(world, points.data(), parts, offsets, local_points.data(), parts[world.rank()], 0);

  // Finding minimum in local vector of points:

  // Find first point satisfied constraints:
  size_t index = 0;
  bool flag_in_area = false;
  while ((index < local_points.size()) && (!flag_in_area)) {
    // Check if constraints is satisfied:
    flag_in_area = true;
    for (size_t j = 0; j < g.size(); j++) {
      if (g[j].calculate(local_points[index]) > 0) {
        flag_in_area = false;
        break;
      }
    }
    index++;
  }
  size_t first_satisfied = index;  // it is first candidate for optimum
  if (first_satisfied == local_points.size()) {
    local_optimum_point = PointWithValue(DBL_MAX, DBL_MAX, DBL_MAX);
  } else {
    local_optimum_point.x = local_points[first_satisfied].x;
    local_optimum_point.y = local_points[first_satisfied].y;
    local_optimum_point.value = q.calculate(local_points[first_satisfied]);
  }

  // Start search from this point:
  for (size_t i = first_satisfied + 1; i < local_points.size(); i++) {
    double current_value = q.calculate(local_points[i]);
    // Check if constraints is satisfied:
    flag_in_area = true;
    for (size_t j = 0; j < g.size(); j++) {
      if (g[j].calculate(local_points[i]) > 0) {
        flag_in_area = false;
        break;
      }
    }
    // Check if current < optimum
    if (flag_in_area) {
      if (current_value < local_optimum_point.value) {
        local_optimum_point.x = local_points[i].x;
        local_optimum_point.y = local_points[i].y;
        local_optimum_point.value = current_value;
      }
    }
  }

  if (world.rank() != 0) {
    boost::mpi::gather(world, local_optimum_point, 0);
  }
  if (world.rank() == 0) {
    std::vector<PointWithValue> optimum_points_vec;
    boost::mpi::gather(world, local_optimum_point, optimum_points_vec, 0);

    local_optimum_point = optimum_points_vec[0];
    for (size_t i = 1; i < optimum_points_vec.size(); i++) {
      if (optimum_points_vec[i].value < local_optimum_point.value) {
        local_optimum_point = optimum_points_vec[i];
      }
    }
  }

  return true;
}
\end{verbatim}

\end{document}