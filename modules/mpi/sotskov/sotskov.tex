\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{tocloft}
\usepackage{xcolor} 
\usepackage{listings}
\usepackage{float}

\geometry{a4paper, left=25mm, right=15mm, top=20mm, bottom=20mm}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=black,
    pdftitle={Отчет по проекту},
    pdfauthor={Соцков Андрей},
    pdfsubject={Поразрядная сортировка для вещественных чисел (тип double) с простым слиянием.}
}

\lstset{
  language=C++,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\itshape\color{green!50!black},
  stringstyle=\color{red!60!black},
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=8pt,
  backgroundcolor=\color{gray!10},
  showspaces=false,
  showstringspaces=false,
  breaklines=true,
  frame=single,
  tabsize=2,
  captionpos=b
}

\renewcommand{\cftsecaftersnum}{.}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\titleformat{\section}{\large\bfseries}{\thesection.}{1em}{}

\begin{document}
\begin{titlepage}
    \centering
    \large
    Министерство науки и высшего образования Российской Федерации\\[0.5cm]
    Федеральное государственное автономное образовательное учреждение высшего образования\\[0.5cm]
    \textbf{«Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»}\\
    (ННГУ)\\[1cm]
    Институт информационных технологий, математики и механики\\[0.5cm]
    Направление подготовки: \textbf{«Программная инженерия»}\\[2cm]

    \vfill % Вертикальное заполнение для центрирования текста
    {\LARGE \textbf{ОТЧЕТ}}\\[0.5cm]
    {\Large по задаче}\\[0.5cm]
    {\LARGE \textbf{«Поразрядная сортировка для вещественных чисел \\[0.3cm] (тип double) с простым слиянием»}}\\[0.5cm]
    {\Large \textbf{Вариант №20}}\\[2.5cm]

    \hfill\parbox{0.5\textwidth}{
        \textbf{Выполнил:} \\
        студент группы 3822Б1ПР3 \\
        \textbf{Соцков Андрей}
    }\\[0.5cm]

    \hfill\parbox{0.5\textwidth}{
        \textbf{Преподаватели:} \\
        Нестеров А.Ю.
        Оболенский А.А.
        
    }\\[2cm]

    Нижний Новгород\\
    2024
\end{titlepage}


\thispagestyle{empty}
\clearpage
\pagenumbering{arabic} 
\setcounter{page}{2} 
\tableofcontents
\clearpage
\setcounter{page}{3} 
\section{Введение}

\hspace*{1.25em}Поразрядная сортировка (Radix Sort) является одним из эффективных алгоритмов сортировки, который работает путем последовательной сортировки элементов по разрядам, начиная с наименьшего значимого разряда. Для вещественных чисел алгоритм требует дополнительной обработки знаков и преобразования чисел в битовое представление.

Использование технологии MPI позволяет ускорить выполнение сортировки на больших наборах данных, благодаря распределению вычислительной нагрузки между несколькими процессорами. Для объединения отсортированных данных между процессами в данной задаче используется метод простого слияния, обеспечивающий корректность конечного результата.

Применение параллельной реализации алгоритма на больших объемах данных позволяет существенно сократить время сортировки по сравнению с последовательным подходом. Для этой задачи ключевым является реализация эффективного распределения данных и минимизация накладных расходов на коммуникацию между процессами.

\section{Постановка задачи}

\hspace*{1.25em} Требуется реализовать алгоритм поразрядной сортировки для вещественных чисел (тип \texttt{double}) с использованием технологии MPI. Реализация должна включать следующие этапы:

\begin{itemize}
    \item Разработка последовательного варианта алгоритма для сортировки массива вещественных чисел.
    \item Реализация параллельного алгоритма с использованием MPI, который распределяет данные между процессами и применяет метод простого слияния для объединения результатов.
    \item Проведение функциональных тестов с использованием Google Test для проверки корректности реализации.
    \item Сравнение времени выполнения последовательной и параллельной реализаций на различных объемах данных.

Целью данной работы является демонстрация эффективности параллельного подхода к сортировке больших массивов вещественных чисел, а также оценка выигрыша по времени по сравнению с традиционным последовательным решением.
\end{itemize}
\section{Описание алгоритма}

\hspace*{1.25em}Общее описание алгоритма поразрядной сортировки для вещественных чисел (тип \texttt{double}) заключается в сортировке чисел с использованием поразрядной техники для положительных и отрицательных чисел отдельно. Алгоритм предполагает разделение чисел на группы по знакам и обработку их с использованием стандартной поразрядной сортировки для целых чисел. Основные этапы алгоритма следующие:

\begin{enumerate} \item \textbf{Предварительная обработка данных}: разделение чисел на положительные и отрицательные. \begin{itemize} \item На первом этапе алгоритма входной массив делится на два подмассива: один с положительными числами, другой — с отрицательными. \item Каждое из этих подмассивов затем обрабатывается отдельно. \end{itemize}
\item \textbf{Поразрядная сортировка положительных чисел}: сортировка значений поразрядным методом для положительных чисел.
\begin{itemize}
    \item Алгоритм сортирует положительные числа, начиная с младших разрядов (битов).
    \item Для каждой цифры/бита (в зависимости от точности представления числа) используется вспомогательная структура данных — корзины (buckets).
    \item Числа последовательно распределяются по корзинам в зависимости от значений соответствующего разряда.
    \item Далее данные собираются обратно из корзин в порядке увеличения значений, что приводит к частично отсортированным данным.
    \item Процесс повторяется для каждого разряда, пока все разряды не будут обработаны.
\end{itemize}

\item \textbf{Поразрядная сортировка отрицательных чисел}: сортировка значений поразрядным методом для отрицательных чисел.
\begin{itemize}
    \item Отрицательные числа также сортируются с использованием того же поразрядного метода.
    \item Однако для отрицательных чисел разряды сортируются так, чтобы на первом этапе числа с меньшими значениями (по абсолютной величине) размещались в начале массива.
    \item Отрицательные числа сортируются по тому же принципу, но с учетом их отрицательного знака.
\end{itemize}

\item \textbf{Объединение отсортированных чисел}: соединение отсортированных подмассивов.
\begin{itemize}
    \item После сортировки положительных и отрицательных чисел они объединяются.
    \item Для этого отрицательные числа помещаются в начале массива в обратном порядке (поскольку они отсортированы по абсолютным величинам), а затем добавляются положительные числа.
\end{itemize}

\item \textbf{Вывод отсортированного массива}: финальная сборка результата.
\begin{itemize}
    \item После выполнения всех этапов сортировки, массив полностью отсортирован.
    \item Он возвращается в итоговом виде в виде единого отсортированного массива.
\end{itemize}

\end{enumerate}
\subsection{Пример работы алгоритма}

\hspace*{1.25em}Пример работы алгоритма для массива вещественных чисел:

\begin{enumerate}
    \item \textbf{Входные данные}: 
    \[
    \{-2.5, 3.2, -1.7, 5.1, 0.3, -3.8\}
    \]

    \item \textbf{Шаг 1 — Разделение на положительные и отрицательные}:
    \[
    \text{Положительные: } [3.2, 5.1, 0.3]
    \]
    \[
    \text{Отрицательные: } [-2.5, -1.7, -3.8]
    \]

    \item \textbf{Шаг 2 — Поразрядная сортировка для положительных чисел}:
    \[
    \text{После обработки каждого разряда: }
    \]
    \[
    \text{Отсортированные положительные: } [0.3, 3.2, 5.1]
    \]

    \item \textbf{Шаг 3 — Поразрядная сортировка для отрицательных чисел}:
    \[
    \text{После обработки каждого разряда: }
    \]
    \[
    \text{Отсортированные отрицательные: } [-3.8, -2.5, -1.7]
    \]

    \item \textbf{Шаг 4 — Объединение отсортированных чисел}:
    \[
    \text{Финальный отсортированный массив: }
    \]
    \[
    [-3.8, -2.5, -1.7, 0.3, 3.2, 5.1]
    \]

    \item \textbf{Шаг 5 — Вывод результата}:
    \[
    \text{Итоговый отсортированный массив: } [-3.8, -2.5, -1.7, 0.3, 3.2, 5.1]
    \]
\end{enumerate}

\section{Алгоритм поразрядной сортировки}

\hspace*{1.25em}Алгоритм поразрядной сортировки для чисел с плавающей запятой типа \texttt{double} с учётом знака и слиянием результатов:

\begin{verbatim}
void radixSortWithSignHandling(std::vector<double>& data) {
  const int num_bits = sizeof(double) * 8;
  const int radix = 2;

  std::vector<double> positives;
  std::vector<double> negatives;

  // Разделение на положительные и отрицательные числа
  for (double num : data) {
    if (num < 0) {
      negatives.push_back(-num);
    } else {
      positives.push_back(num);
    }
  }

  // Сортировка положительных и отрицательных чисел
  radixSort(positives, num_bits, radix);
  radixSort(negatives, num_bits, radix);

  // Восстановление знака у отрицательных чисел
  for (double& num : negatives) {
    num = -num;
  }

  // Объединение отрицательных и положительных чисел
  data.clear();
  data.insert(data.end(), negatives.rbegin(), negatives.rend());
  data.insert(data.end(), positives.begin(), positives.end());
}

void radixSort(std::vector<double>& data, int num_bits, int radix) {
  std::vector<std::vector<double>> buckets(radix);
  std::vector<double> output(data.size());

  // Поразрядная сортировка
  for (int exp = 0; exp < num_bits; ++exp) {
    for (auto& num : data) {
      uint64_t bits = *reinterpret_cast<uint64_t*>(&num);
      int digit = (bits >> exp) & 1;
      buckets[digit].push_back(num);
    }

    int index = 0;
    for (int i = 0; i < radix; ++i) {
      for (auto& num : buckets[i]) {
        output[index++] = num;
      }
      buckets[i].clear();
    }

    data = output;
  }
}
\end{verbatim}

\hspace*{1.25em}В этом коде:
\begin{itemize}
    \item \texttt{radixSortWithSignHandling()} разделяет данные на положительные и отрицательные числа, сортирует их по разрядам и затем объединяет с учётом знака.
    \item \texttt{radixSort()} выполняет стандартную поразрядную сортировку с использованием вспомогательных корзин.
\end{itemize}


\section{Описание схемы распараллеливания}

\hspace*{1.25em}Схема распараллеливания алгоритма поразрядной сортировки основывается на следующих этапах:

\begin{enumerate}
    \item \textbf{Предобработка данных}: На первом этапе входной массив данных разделяется между процессами. Процесс с рангом $0$ считывает массив и с помощью MPI операцией \texttt{MPI\_Scatterv} распределяет его на подмассивы, которые обрабатываются параллельно на различных процессах. Каждый процесс работает с частью данных, что позволяет распараллелить выполнение алгоритма на всех доступных процессах.

    \item \textbf{Локальная сортировка данных}: Каждый процесс выполняет локальную сортировку своей части массива с использованием поразрядной сортировки. Для этого массив делится на два подмассива: положительные и отрицательные числа. Каждая часть сортируется отдельно с помощью поразрядной сортировки. Для отрицательных чисел используется механизм инвертирования знака, чтобы после сортировки вернуть их в правильный порядок.

    \item \textbf{Объединение отсортированных частей}: После локальной сортировки каждый процесс отправляет отсортированные данные обратно процессу с рангом $0$. Процесс $0$ затем выполняет простое слияние данных от всех процессов, используя стандартную функцию \texttt{std::merge}. Это объединение проводится поочередно для каждого процесса, и результат записывается в итоговый массив.

    \item \textbf{Распределение итоговых данных}: После того как данные объединены и отсортированы, итоговый массив передается всем процессам с помощью MPI операции \texttt{MPI\_Bcast}. Это позволяет каждому процессу иметь доступ к отсортированному массиву.
\end{enumerate}

\hspace*{1.25em}Таким образом, схема распараллеливания позволяет эффективно использовать ресурсы многопроцессорной системы, выполняя сортировку больших массивов данных за счет распределенной обработки данных на различных процессах и последующего слияния результатов.

\hspace*{1.25em}Важными аспектами распараллеливания являются:
\begin{itemize}
    \item \textbf{Распределение данных}: Каждый процесс работает с подмассивом данных, что позволяет эффективно использовать вычислительные ресурсы.
    \item \textbf{Сортировка с учетом знаков}: Отдельная сортировка для положительных и отрицательных чисел способствует корректному результату при объединении.
    \item \textbf{Механизм слияния}: Использование стандартного слияния для объединения отсортированных частей массива позволяет избежать сложных операций на этапе слияния.
\end{itemize}




\section{Программная реализация}


\subsubsection*{Pre-processing}
\begin{itemize}
    \item На корневом процессе загружаются данные массива, который требуется отсортировать.
    \item Данные преобразуются в линейный массив, который будет распределён между процессами.
\end{itemize}

\subsubsection*{Validation}
\begin{itemize}
    \item Выполняется проверка корректности входных данных на корневом процессе:
    \begin{itemize}
        \item Размер данных должен быть больше нуля.
        \item Массив данных должен быть корректно инициализирован.
        \item Буферы для результатов (выходные данные) должны быть доступны.
    \end{itemize}
\end{itemize}

\subsubsection*{Run}

\begin{enumerate}
    \item \textbf{Инициализация процессов}: 
    \begin{itemize}
        \item Все процессы начинают работу с одинаковыми данными. Корневой процесс (процесс с \texttt{rank == 0}) инициализирует данные и передаёт их остальным процессам с помощью \texttt{MPI\_Scatter}.
    \end{itemize}

    \item \textbf{Этапы выполнения}: 
    \begin{enumerate}
        \item[a.] \textbf{Распределение данных}:
        \begin{itemize}
            \item Корневой процесс делит исходный массив на равные блоки и передаёт эти блоки всем участникам с помощью \texttt{MPI\_Scatter}. Каждый процесс получает свою часть данных для дальнейшей локальной сортировки.
        \end{itemize}

        \item[b.] \textbf{Локальная сортировка}:
        \begin{itemize}
            \item Каждый процесс выполняет поразрядную сортировку на своём локальном наборе данных с использованием алгоритма \texttt{radixSortWithSignHandling}.
            \item Алгоритм выполняет сортировку поразрядным способом с обработкой знаков для чисел.
        \end{itemize}

        \item[c.] \textbf{Обмен данными}:
        \begin{itemize}
            \item После локальной сортировки каждый процесс выполняет обмен данными с соседними процессами для слияния отсортированных блоков. Для обмена используется \texttt{MPI\_Sendrecv}, что позволяет эффективно обмениваться данными между процессами.
        \end{itemize}

        \item[d.] \textbf{Слияние результатов}:
        \begin{itemize}
            \item Локально отсортированные данные сливаются с результатами других процессов. Для этого используется стандартная операция слияния, основанная на \texttt{std::merge}.
            \item Корневой процесс собирает финальные данные с помощью \texttt{MPI\_Gather} и восстанавливает окончательный отсортированный массив.
        \end{itemize}
    \end{enumerate}
\end{enumerate}

\subsubsection*{Post-processing}
\begin{itemize}
    \item Корневой процесс копирует финальный отсортированный массив в выходной буфер для дальнейшего использования или сохранения.
\end{itemize}

\subsubsection*{Ключевые особенности реализации}
\begin{itemize}
    \item Использование MPI для параллельной обработки данных на множестве процессов ускоряет выполнение поразрядной сортировки для больших объёмов данных.
    \item Процесс обмена данными между процессами осуществляется с использованием \texttt{MPI\_Sendrecv}, что минимизирует накладные расходы на передачу данных и синхронизацию.
    \item Каждый процесс выполняет локальную сортировку, а затем все процессы совместно объединяют результаты, что даёт существенное ускорение по сравнению с последовательной реализацией.
    \item Алгоритм адаптирован под топологию, в которой каждый процесс может работать независимо и выполняет обмен данными для слияния отсортированных блоков.
\end{itemize}

\subsubsection*{Ключевые особенности реализации}
\begin{itemize}
    \item Алгоритм эффективно работает с большими объёмами данных, эффективно используя возможности многопроцессорных систем с параллельной обработкой.
    \item Использование \texttt{MPI\_Sendrecv} минимизирует накладные расходы на передачу данных между процессами.
    \item Каждый процесс выполняет локальную сортировку, а затем все процессы совместно объединяют результаты, что даёт существенное ускорение по сравнению с последовательной реализацией.
\end{itemize}



\section{Результаты экспериментов}

Для оценки производительности алгоритма поразрядной сортировки для вещественных чисел (тип double) с простым слиянием были проведены измерения времени выполнения последовательной реализации и параллельной реализации с использованием MPI. Результаты тестирования приведены в таблице ниже:
\begin{table}[H]
\centering
\caption{Результаты тестирования алгоритма поразрядной сортировки для вещественных чисел с простым слиянием для различных количеств процессов}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Количество процессов} & \textbf{Вид теста} & \textbf{Время (мс)} & \textbf{Ускорение} \\
\hline
1 & test\_pipeline\_run & 1418 & 1.20 \\
\hline
1 & test\_task\_run & 1542 & 1.61 \\
\hline
1 & Общее время & 2961 & 1.38 \\
\hline
2 & test\_pipeline\_run & 1179 & 1.71 \\
\hline
2 & test\_task\_run & 960  & 1.60 \\
\hline
2 & Общее время & 2140 & 1.38 \\
\hline
3 & test\_pipeline\_run & 941  & 1.51 \\
\hline
3 & test\_task\_run & 689  & 2.24 \\
\hline
3 & Общее время & 1631 & 1.81 \\
\hline
4 & test\_pipeline\_run & 821  & 1.73 \\
\hline
4 & test\_task\_run & 572  & 2.69 \\
\hline
4 & Общее время & 1393 & 2.13 \\
\hline
5 & test\_pipeline\_run & 775  & 1.83 \\
\hline
5 & test\_task\_run & 505  & 3.05 \\
\hline
5 & Общее время & 1281 & 2.31 \\
\hline
6 & test\_pipeline\_run & 697  & 2.04 \\
\hline
6 & test\_task\_run & 438  & 3.52 \\
\hline
6 & Общее время & 1136 & 2.61 \\
\hline
7 & test\_pipeline\_run & 703  & 2.02 \\
\hline
7 & test\_task\_run & 417  & 3.70 \\
\hline
7 & Общее время & 1122 & 2.64 \\
\hline
8 & test\_pipeline\_run & 673  & 2.11 \\
\hline
8 & test\_task\_run & 386  & 4.00 \\
\hline
8 & Общее время & 1060 & 2.79 \\
\hline
\end{tabular}
\label{tab:performance_results}
\end{table}





\section{Выводы из результатов}

\hspace*{1.25em}Из данных, представленных в Таблице 1, можно сделать несколько важных выводов о производительности параллельной реализации алгоритма поразрядной сортировки для вещественных чисел с простым слиянием с использованием MPI.

\hspace*{1.25em}Во-первых, наблюдается значительное ускорение выполнения по мере увеличения количества процессов. Например, для последовательной реализации (1 процесс) общее время выполнения составляет 2961 мс, в то время как для 8 процессов оно снижается до 1060 мс, что является улучшением в 2.79 раза. Это подтверждает, что параллельная реализация алгоритма эффективно использует возможности многозадачности и ускоряет обработку данных.

\hspace*{1.25em}Во-вторых, следует отметить, что ускорение не является линейным. С увеличением числа процессов ускорение стабилизируется. Например, при переходе от 5 до 8 процессов наблюдается лишь незначительное улучшение производительности (ускорение от 2.31 до 2.79). Это явление объясняется тем, что при слишком большом числе процессов возникает рост накладных расходов на передачу данных между процессами, что в итоге снижает прирост производительности.

\hspace*{1.25em}Также стоит отметить, что наибольшие значения ускорения достигаются при переходе от 1 к 2 или 3 процессам, когда эффективность распределения задач между процессами наиболее заметна. В дальнейшем прирост ускорения замедляется из-за увеличения накладных расходов на управление процессами и коммуникацию.

\hspace*{1.25em}Таким образом, для оптимальной производительности алгоритма поразрядной сортировки с простым слиянием следует выбирать количество процессов в пределах от 6 до 8, где ускорение наиболее заметно, а накладные расходы на коммуникацию между процессами еще не становятся доминирующими.

Эксперименты проводились на следующей системе:
\begin{itemize}
    \item Операционная система: Windows 11.
    \item Процессор: 12th Gen Intel(R) Core(TM) i5-12400F, 6 ядер.
    \item Оперативная память: 32 ГБ.
\end{itemize}


\section{Заключение}

\hspace*{1.25em}В ходе выполнения данной работы была реализована параллельная версия алгоритма поразрядной сортировки для вещественных чисел (тип \texttt{double}) с применением простого слияния и технологии MPI. Реализация алгоритма позволила применить параллельные вычисления для оптимизации времени выполнения сортировки, что особенно важно при работе с большими массивами данных. Для гарантии правильности работы программы были проведены функциональные тесты, результаты которых подтвердили корректность реализации алгоритма.

Важной частью работы было также исследование производительности параллельной реализации по сравнению с её последовательной версией. Для этого были проведены эксперименты с использованием данных фиксированного размера, в частности, на массиве из вещественных чисел. Результаты тестирования показали значительное ускорение параллельной версии по сравнению с последовательной, что указывает на эффективность использования параллельных вычислений для решения задачи сортировки. Ускорение возрастает с увеличением количества процессов, что подтверждает правильность алгоритма распределения задач между процессами.

Однако, следует отметить, что при увеличении числа процессов прирост производительности начинает замедляться. Это связано с ростом накладных расходов на коммуникацию между процессами и управлением вычислениями, что ограничивает дальнейшее улучшение производительности. Таким образом, параллельная реализация алгоритма демонстрирует хорошее ускорение при разумном количестве процессов, но с увеличением числа процессов возможен эффект насыщения.

В итоге, поставленная задача была успешно решена: алгоритм поразрядной сортировки был реализован, проведено сравнение его производительности в параллельной и последовательной версиях, и получены обоснованные выводы о преимуществах параллельной обработки данных. Результаты экспериментов подчеркивают важность использования параллельных вычислений для эффективной работы с большими массивами данных и могут служить основой для дальнейших исследований в области параллельных алгоритмов сортировки.


\section*{Литература}

\begin{enumerate}
    \item \href{https://thecode.media/radix/}{Thecode media. "Radix Sort — самая быстрая сортировка для чисел и строк." }.
    \item \href{https://habr.com/ru/articles/548266/5}{Habr. "MPI — Введение и первая программа"}.
     \item \href{https://htmlacademy.ru/blog/html_old}{Htmlacademy. "Бесплатный учебник по GIT и GitHub"}.
\end{enumerate}


\appendix
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}

В данном разделе представлены основные фрагменты реализации алгоритма Поразрядной сортировки.
\subsection*{Функция TestMPITaskSequential::sequentialSort}

\begin{lstlisting}[language=C++]
void sotskov_a_radix_sort_for_numbers_type_double_with_simple_merging_mpi::TestMPITaskSequential::sequentialSort() {
  sorted_data_ = input_data_;
  radixSortWithSignHandling(sorted_data_);
}
\end{lstlisting}


\subsection*{Функция radixSortWithSignHandling}

\begin{lstlisting}[language=C++]
void sotskov_a_radix_sort_for_numbers_type_double_with_simple_merging_mpi::radixSortWithSignHandling(
    std::vector<double>& data) {
  const int num_bits = sizeof(double) * 8;
  const int radix = 2;

  std::vector<double> positives;
  std::vector<double> negatives;

  for (double num : data) {
    if (num < 0) {
      negatives.push_back(-num);
    } else {
      positives.push_back(num);
    }
  }

  radixSort(positives, num_bits, radix);
  radixSort(negatives, num_bits, radix);

  for (double& num : negatives) {
    num = -num;
  }

  data.clear();
  data.insert(data.end(), negatives.rbegin(), negatives.rend());
  data.insert(data.end(), positives.begin(), positives.end());
}

void sotskov_a_radix_sort_for_numbers_type_double_with_simple_merging_mpi::radixSort(std::vector<double>& data, int num_bits, int radix) {
  std::vector<std::vector<double>> buckets(radix);
  std::vector<double> output(data.size());

  for (int exp = 0; exp < num_bits; ++exp) {
    for (auto& num : data) {
      uint64_t bits = *reinterpret_cast<uint64_t*>(&num);
      int digit = (bits >> exp) & 1;
      buckets[digit].push_back(num);
    }

    int index = 0;
    for (int i = 0; i < radix; ++i) {
      for (auto& num : buckets[i]) {
        output[index++] = num;
      }
      buckets[i].clear();
    }

    data = output;
  }
}
\end{lstlisting}

\subsection*{Функция TestMPITaskParallel::parallelSort}

\begin{lstlisting}[language=C++]
void sotskov_a_radix_sort_for_numbers_type_double_with_simple_merging_mpi::TestMPITaskParallel::parallelSort() {
  int total_size;
  if (rank == 0) total_size = input_data_.size();
  MPI_Bcast(&total_size, 1, MPI_INT, 0, MPI_COMM_WORLD);

  std::vector<int> send_counts(size);
  std::vector<int> displacements(size);

  int base_size = total_size / size;
  int remainder = total_size % size;

  for (int i = 0; i < size; ++i) {
    send_counts[i] = base_size + (i < remainder ? 1 : 0);
    displacements[i] = (i > 0) ? (displacements[i - 1] + send_counts[i - 1]) : 0;
  }

  std::vector<double> local_data(send_counts[rank]);
  MPI_Scatterv(input_data_.data(), send_counts.data(), displacements.data(), MPI_DOUBLE, local_data.data(),
               send_counts[rank], MPI_DOUBLE, 0, MPI_COMM_WORLD);

  radixSortWithSignHandling(local_data);

  if (rank == 0) {
    std::vector<double> recv_data(base_size + 1);
    std::vector<double> merged_data;
    sorted_data_ = local_data;

    MPI_Status status;
    merged_data.reserve(total_size);
    for (int proc = 1; proc < size; proc++) {
      MPI_Recv(recv_data.data(), send_counts[proc], MPI_DOUBLE, proc, 0, MPI_COMM_WORLD, &status);
      std::merge(sorted_data_.begin(), sorted_data_.end(), recv_data.begin(), recv_data.begin() + send_counts[proc],
                 std::back_inserter(merged_data));
      sorted_data_ = merged_data;
      merged_data.clear();
    }
  } else {
    MPI_Send(local_data.data(), local_data.size(), MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);
  }

  MPI_Barrier(MPI_COMM_WORLD);
}
\end{lstlisting}

\clearpage
\subsection*{Функция TestMPITaskSequential::run}

\begin{lstlisting}[language=C++]
bool sotskov_a_radix_sort_for_numbers_type_double_with_simple_merging_mpi::TestMPITaskSequential::run() {
  internal_order_test();
  sequentialSort();

  return true;
}
\end{lstlisting}
\end{document}