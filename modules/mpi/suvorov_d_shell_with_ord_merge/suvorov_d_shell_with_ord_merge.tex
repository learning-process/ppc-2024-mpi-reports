\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage{graphicx}

\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}

\usepackage{xcolor}
\lstset{
    language=C++, 
    basicstyle=\ttfamily\small, 
    keywordstyle=\color{blue}\bfseries, 
    stringstyle=\color{orange}, 
    commentstyle=\color{green!50!black}\itshape, 
    morecomment=[l][\color{purple}]{\#}, 
    tabsize=2, 
    breaklines=true, 
    breakatwhitespace=false, 
    frame=single, 
    title=\lstname,
    showstringspaces=false, 
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\Large Отчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large «Сортировка Шелла с простым слиянием»} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнил:} \\ студент группы 3822Б1ФИ1 \\ Суворов Дмитрий Ильич\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ канд. техн. наук \\ Сысоев А.В.\\}
\vspace{\fill}

\begin{center} Нижний Новгород \\ 2024 \end{center}

\end{titlepage}

\setcounter{page}{2}
\tableofcontents

\newpage

\newpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}

Сортировка данных является одной из ключевых задач в области компьютерных наук, обеспечивая основу для эффективной обработки информации в различных приложениях. Среди множества алгоритмов сортировки алгоритм Шелла занимает особое место благодаря своей универсальности и сравнительно высокой производительности на средних объемах данных. Однако с ростом объема данных и усложнением вычислительных задач требования к скорости выполнения таких алгоритмов становятся всё более строгими. Именно поэтому исследование возможностей их ускорения, включая распараллеливание, приобретает особую актуальность. 

Алгоритм Шелла, изначально предложенный Дональдом Шеллом в 1959 году, привлекателен своей простотой и гибкостью. Его основная идея — использование промежуточной сортировки с уменьшающимся шагом — позволяет значительно сократить количество обменов в финальной фазе упорядочивания. В данной работе рассматривается реализация этого алгоритма в распределённой среде с использованием библиотеки Boost.MPI. Такой подход позволяет исследовать эффективность применения параллельных вычислений для уменьшения времени выполнения сортировки при обработке больших объемов данных.

\newpage

\section*{Постановка задачи}  
\addcontentsline{toc}{section}{Постановка задачи}  

Дано множество данных, представленных в виде массива из $n$ элементов:

\[
D = \{ d_1, d_2, d_3, \dots, d_n \}
\]

Необходимо реализовать параллельную версию алгоритма сортировки Шелла с использованием библиотеки \texttt{boost.mpi}. Сортировка массива данных должна производиться параллельно в несколько процессов. Результаты сортировки каждого процесса должны объединяться в единый итоговый массив данных с помощью алгоритма простого слияния.

Входные данные:
\begin{itemize}
    \item Массив целых чисел $D = \{ d_1, d_2, d_3, \dots, d_n \}$, где $n$ — количество элементов в массиве.
\end{itemize}

Выходные данные:
\begin{itemize}
    \item Отсортированный массив $D$, в котором элементы упорядочены в возрастающем порядке.
\end{itemize}

Алгоритм должен быть реализован с использованием \texttt{boost.mpi} для параллельной обработки данных, обеспечивая корректную синхронизацию между процессами и эффективное распределение вычислительных ресурсов.

\newpage
\section*{Описание алгоритмов}
\addcontentsline{toc}{section}{Описание алгоритмов}

\subsection*{Алгоритм сортировки Шелла}

Алгоритм сортировки Шелла представляет собой улучшение простого алгоритма сортировки вставками. Сортировка Шелла, в отличии от предшественника, позволяет сначала проводить сравнения и перестановки элементов, которые расположены на большем расстоянии друг от друга. Это ускоряет процесс, так как элементы, которые должны быть перемещены на большие расстояния, могут быть быстро сдвинуты ближе к нужным местам. По мере уменьшения шага между сравниваемыми элементами алгоритм становится более точным, доводя массив до полной сортировки.

\subsubsection*{Алгоритм}
Инициализация расстояния (gap): Алгоритм начинает с выбора расстояния (или шага) $gap$, которое изначально равно половине размера массива. С каждым шагом алгоритм уменьшает $gap$, обычно деля его пополам. Процесс продолжается, пока $gap$ не станет равным 1.

Процесс сортировки: На каждом шаге с определённым $gap$ алгоритм рассматривает элементы массива, которые находятся на расстоянии $gap$ друг от друга. Для каждого элемента массива начиная с индекса $gap$, он сравнивается с элементом, расположенным на расстоянии $gap$ раньше. Если элемент на текущей позиции больше, чем элемент на $gap$ позиций раньше, то они меняются местами.

Повторение процесса: Процесс сравнения и перестановки продолжается для всех элементов, начиная с $gap$-го и до конца массива. После этого шаг $gap$ уменьшается в два раза, и процесс повторяется для нового значения $gap$.

Заключительный этап: Когда $gap$ становится равным 1, алгоритм выполняет окончательную сортировку с шагом 1, что эквивалентно обычной сортировке вставками.

Таким образом, алгоритм Шелла устраняет большие элементы в начале массива, улучшая производительность стандартной сортировки вставками. Чем меньше шаг, тем более детализированным становится процесс сортировки, и в конечном итоге массив становится отсортированным.

\subsubsection*{Сложность алгоритма}
Время работы алгоритма Шелла зависит от последовательности шагов (\texttt{gap}), которую выбирает пользователь. Для самой простой последовательности шагов, которая и будет реализована в рамках этой работы, $gap$ уменьшается в два раза на каждом шаге и сложность алгоритма может быть оценена как $O(n^2)$. Однако, существуют другие более оптимизированные последовательности шагов, например, последовательность Хиббарда ($gap = 1, 3, 7, 15, \dots$), то сложность может быть улучшена до $O(n^{3/2})$.

В случае использования других последовательностей шагов (например, Токуджи или Седжвика) сложность может быть еще более низкой. Для некоторых последовательностей шагов, таких как последовательность Седжвика, сложность может достигать $O(n \log^2 n)$, что значительно быстрее для больших массивов по сравнению с традиционными методами сортировки, такими как сортировка вставками.

Таким образом, время работы алгоритма Шелла сильно зависит от выбора последовательности шагов, и оптимизированные последовательности позволяют достичь значительно лучшей производительности.

\subsection*{Алгоритм простого слияния}

\subsubsection*{Алгоритм}
Алгоритм простого слияния используется для объединения двух отсортированных массивов (или частей массива) в один отсортированный массив.

Процесс слияния начинается с того, что два отсортированных массива (например, \texttt{left} и \texttt{right}) объединяются в один отсортированный массив \texttt{result}. Для этого используются три индекса: \texttt{i}, \texttt{j} и \texttt{k}, которые отслеживают текущие позиции в массивах \texttt{left}, \texttt{right} и \texttt{result} соответственно.

1. Сравнение элементов: Изначально \texttt{i} и \texttt{j} устанавливаются на 0, а \texttt{k} также на 0. Далее, пока не достигнут конец одного из массивов, элементы с индексами \texttt{i} и \texttt{j} сравниваются. Меньший элемент копируется в массив \texttt{result}, а индекс этого элемента увеличивается. Процесс продолжается до тех пор, пока не останется элементов в одном из массивов.

2. Дополнение оставшихся элементов: После завершения основного цикла наименьший из массивов (\texttt{left} или \texttt{right}) полностью обработан. Оставшиеся элементы другого массива копируются в \texttt{result} без дополнительных сравнений, так как они уже отсортированы. Все элементы в \texttt{result} на момент завершения алгоритма будут отсортированы.

В результате получается отсортированный массив, объединяющий элементы из двух исходных массивов.

\subsubsection*{Сложность алгоритма}
Алгоритм простого слияния имеет временную сложность $O(n)$, где $n$ — это общее количество элементов в объединяемых массивах. Это объясняется тем, что каждый элемент обоих массивов обрабатывается ровно один раз. 

Сложность алгоритма $O(n)$ делает его эффективным для объединения двух отсортированных частей массива.

\newpage
\section*{Описание схемы распараллеливания}
\addcontentsline{toc}{section}{Описание схемы распараллеливания}

Для распараллеливания алгоритма сортировки Шелла используется подход, основанный на разбиении данных на части и их распределении между процессами с помощью библиотеки Boost.MPI. Схема распараллеливания следующая:

1. Передача размера данных: Первый процесс (с рангом 0) передает всем процессам количество сортируемых данных.

2. Разделение данных: Данные делятся на части для каждого процесса по следующему принципу:
\begin{itemize}
     \item Вычисляется размер "равной" части данных для каждого процесса (целая часть от результата деления количества данных на количество процессов).
     \item Затем размеры частей для процессов, индекс которых меньше остатка от деления количества данных на количество процессов, чтобы учесть переполнение.
     \item Также вычисляются смещения для каждого процесса, то есть, начиная с какого индекса в исходном массиве данных каждый процесс будет получать свои данные для сортировки.
     \item Каждому процессу отправляется часть данных из исходного массива по соответствующим значениям размера части, смещения от начала
\end{itemize}

4. Сортировка локальных данных: Каждый процесс сортирует свои части данных с помощью описанного алгоритма сортировки Шелла. 

5. Сборка отсортированных данных: После сортировки локальных частей данных, процессы собирают свои отсортированные части обратно на процессе с рангом 0. Все данные собираются в одном массиве, на основании заранее вычисленных размеров и смещений.

6. Слияние отсортированных частей: На процессе с рангом 0 данные из разных частей объединяются в один отсортированный массив с помощью алгоритма простого слияния. Для этого используется последовательное слияние частей, полученных от разных процессов, с использованием временного буфера, в который записывается результат слияния уже слитой части массива с новой обрабатываемой частью. Данные временного буффера кладутся в результирующий массив отсортированных данных.

Таким образом, каждый процесс обрабатывает лишь часть данных, что позволяет ускорить выполнение алгоритма сортировки при больших объемах данных. На последнем этапе происходит последовательное слияние отсортированных частей данных, что завершает процесс сортировки.

\newpage
\section*{Результаты вычислительных эекспериментов}
\addcontentsline{toc}{section}{Результаты вычислительных эекспериментов}

Целью эксперимента было сравнение производительности параллельной и последовательной версий алгоритма сортировки на массиве из 10 миллионов случайных элементов, заранее отсортированных в обратном порядке (тестирование худшего случая).

\subsection*{Результаты времени выполнения}
Эксперимент проводился на компьютере с характеристиками:
\begin{itemize}
    \item \textbf{Имя устройства:} MSI
    \item \textbf{Процессор:} 12th Gen Intel(R) Core(TM) i7-1255U 1.70GHz
    \item \textbf{Оперативная память:} 16,0 ГБ (доступно: 15,7 ГБ)
\end{itemize}

\subsection*{Результаты времени выполнения}

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{|c|c|c|}
\hline
\textbf{Номер теста} & \textbf{Последовательная версия (мс)} & \textbf{Параллельная версия (мс)} \\
\hline
1 & 2561.52 & 1863.89 \\
2 & 2720.67 & 1918.78 \\
3 & 2642.17 & 1851.26 \\
4 & 2571.34 & 1836.67 \\
5 & 2746.97 & 1902.37 \\
\hline
\end{tabular}
}
\caption{Результаты времени выполнения сортировки для последовательной и параллельной версии}
\end{table}

\subsection*{Анализ результатов}

Из таблицы видно, что параллельная версия алгоритма сортировки (при использовании 4 процессов) показывает лучшие результаты по времени выполнения по сравнению с последовательной версией. Среднее время работы параллельной версии составило 1.87 секунды, что заметно быстрее, чем среднее время работы последовательной версии, которое составило 2.69 секунды. Таким образом, ускорение параллельной версии по сравнению с последовательной составляет примерно \( \frac{2.69}{1.87} \approx 1.44 \) раза. Это подтверждает, что использование параллельной обработки позволяет значительно ускорить процесс сортировки для больших массивов данных.

\newpage

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}

В ходе данной работы была проведена реализация и анализ алгоритма сортировки Шелла, как в последовательной, так и в параллельной версиях. Параллельная версия была реализована с использованием библиотеки Boost.MPI, что позволило эффективно распределить нагрузку между несколькими процессами.

Тестирование на массивах данных, отсортированных в обратном порядке, показало, что параллельная версия алгоритма значительно ускоряет процесс сортировки, особенно на больших объемах данных. В экспериментах с массивом из 10 миллионов элементов и использовании 4 процессов параллельная версия показала улучшение времени выполнения на 44\%, что подтверждает эффективность параллельных вычислений для задач сортировки. 

Результаты эксперимента демонстрируют, что использование параллельных вычислений позволяет существенно сократить время выполнения задачи, что является важным фактором при работе с большими объемами данных. Однако, для дальнейших улучшений, можно рассмотреть другие алгоритмы сортировки и методы оптимизации параллельных вычислений.

\newpage
\begin{thebibliography}{1}
  \addcontentsline{toc}{section}{Литература}
  \bibitem{habr_article} Хабр. (2018, 2 июля). \textit{Сортировка Шелла}. Habr. https://habr.com/ru/articles/415935/

  \bibitem{boost_mpi} Boost C++ Libraries. (n.d.). \textit{Boost.MPI}. https://www.boost.org/doc/libs/1\_76\_0/doc/html/mpi.html

  \bibitem{sorting_algorithms} Knuth, D. (1998). \textit{The Art of Computer Programming, Volume 3: Sorting and Searching}. Addison-Wesley.
  \end{thebibliography}
\newpage

\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
\section*{Интерфейс}

\begin{lstlisting}[language=C++, caption={Интерфейс}]
namespace suvorov_d_shell_with_ord_merge_mpi {

std::vector<int> shell_sort(const std::vector<int>&);
void merge_vectors(const std::vector<int>& left, const std::vector<int>& right, std::vector<int>& result);

class TaskShellSortParallel : public ppc::core::Task {
 public:
  explicit TaskShellSortParallel(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
  bool pre_processing() override;
  bool validation() override;
  bool run() override;
  bool post_processing() override;

 private:
  std::vector<int> data_to_sort, sorted_data, partial_data;
  boost::mpi::communicator world;
};

}  // namespace suvorov_d_shell_with_ord_merge_mpi
\end{lstlisting}

\section*{Реализация}

\begin{lstlisting}[language=C++, caption={Реализация}]
std::vector<int> suvorov_d_shell_with_ord_merge_mpi::shell_sort(const std::vector<int>& vec_to_sort) {
  std::vector<int> result_vec = vec_to_sort;
  size_t n = result_vec.size();

  for (size_t gap = n / 2; gap > 0; gap /= 2) {
    for (size_t i = gap; i < n; ++i) {
      int curr_val = result_vec[i];
      size_t j = i;

      while (j >= gap && result_vec[j - gap] > curr_val) {
        result_vec[j] = result_vec[j - gap];
        j -= gap;
      }
      result_vec[j] = curr_val;
    }
  }

  return result_vec;
}

void suvorov_d_shell_with_ord_merge_mpi::merge_vectors(const std::vector<int>& left, const std::vector<int>& right,
                                                       std::vector<int>& result) {
  size_t i = 0;
  size_t j = 0;
  size_t k = 0;

  result.resize(left.size() + right.size());
  while (i < left.size() && j < right.size()) {
    if (left[i] <= right[j]) {
      result[k++] = left[i++];
    } else {
      result[k++] = right[j++];
    }
  }

  while (i < left.size()) {
    result[k++] = left[i++];
  }

  while (j < right.size()) {
    result[k++] = right[j++];
  }
}

bool suvorov_d_shell_with_ord_merge_mpi::TaskShellSortParallel::pre_processing() {
  internal_order_test();

  if (world.rank() == 0) {
    auto data_size = static_cast<size_t>(taskData->inputs_count[0]);
    int* data_tmp_ptr = reinterpret_cast<int*>(taskData->inputs[0]);
    data_to_sort.assign(data_tmp_ptr, data_tmp_ptr + data_size);
  }

  return true;
}

bool suvorov_d_shell_with_ord_merge_mpi::TaskShellSortParallel::validation() {
  internal_order_test();
  if (world.rank() == 0) {
    return taskData->inputs_count[0] > 0 && taskData->outputs_count[0] > 0 && taskData->inputs_count.size() == 1 &&
           taskData->outputs_count.size() == 1 && taskData->inputs_count[0] == taskData->outputs_count[0];
  }
  return true;
}

bool suvorov_d_shell_with_ord_merge_mpi::TaskShellSortParallel::run() {
  internal_order_test();

  int data_size = 0;
  if (world.rank() == 0) {
    data_size = data_to_sort.size();
  }
  boost::mpi::broadcast(world, data_size, 0);

  int uniform_part_size = data_size / world.size();
  int overflow_size = data_size % world.size();

  std::vector<int> sizes(world.size(), uniform_part_size);

  std::transform(sizes.begin(), sizes.begin() + overflow_size, sizes.begin(), [](int size) { return size + 1; });

  std::vector<int> displacements(world.size(), 0);
  std::partial_sum(sizes.begin(), sizes.end() - 1, displacements.begin() + 1);

  int local_size = sizes[world.rank()];
  partial_data.resize(local_size);

  if (world.rank() == 0) {
    boost::mpi::scatterv(world, data_to_sort.data(), sizes, displacements, partial_data.data(), local_size, 0);
  } else {
    boost::mpi::scatterv(world, partial_data.data(), local_size, 0);
  }

  partial_data = suvorov_d_shell_with_ord_merge_mpi::shell_sort(partial_data);

  std::vector<int> merge_data;
  if (world.rank() == 0) {
    merge_data.resize(data_size);
  }
  boost::mpi::gatherv(world, partial_data.data(), sizes[world.rank()], merge_data.data(), sizes, displacements, 0);

  if (world.rank() == 0) {
    std::vector<int> tmp_buff;
    sorted_data.assign(merge_data.begin(), merge_data.begin() + sizes[0]);

    for (int i = 1; i < world.size(); ++i) {
      auto start = merge_data.begin() + displacements[i];
      auto end = start + sizes[i];

      suvorov_d_shell_with_ord_merge_mpi::merge_vectors(sorted_data, std::vector<int>(start, end), tmp_buff);

      sorted_data = std::move(tmp_buff);
    }
  }

  return true;
}

bool suvorov_d_shell_with_ord_merge_mpi::TaskShellSortParallel::post_processing() {
  internal_order_test();
  if (world.rank() == 0) {
    std::copy(sorted_data.begin(), sorted_data.end(), reinterpret_cast<int*>(taskData->outputs[0]));
  }
  return true;
}
\end{lstlisting}
    \end{document}