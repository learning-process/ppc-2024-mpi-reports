\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[english, russian]{babel}
\usepackage[utf8]{luainputenc}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{amsmath}

\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\lstset{
    language=C++, 
    basicstyle=\ttfamily\small, 
    keywordstyle=\color{blue}\bfseries, 
    stringstyle=\color{orange}, 
    commentstyle=\color{green!50!black}\itshape, 
    morecomment=[l][\color{purple}]{\#}, 
    tabsize=2, 
    breaklines=true, 
    breakatwhitespace=false, 
    frame=single, 
    showstringspaces=false, 
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\Large Отчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large «Построение выпуклой оболочки для компонент бинарного изображения»} \\
\end{center}

\vspace{4em}

\hfill\parbox{7cm}{
\textbf{Выполнил:} \\ 
студент группы 3822Б1ФИ3 \\ 
Фролова Елизавета\\
\\
\textbf{Проверил:}\\ 
доцент кафедры МОСТ, \\ 
кандидат технических наук \\ 
Сысоев А.В.\\}

\vspace{\fill}

\begin{center} Нижний Новгород \\ 2024 \end{center}

\end{titlepage}

\setcounter{page}{2}
\tableofcontents

\newpage
\section*{Введение}
\addcontentsline{toc}{section}{Введение}

Численное вычисление многомерных интегралов является важной задачей в прикладной математике, физике, компьютерной графике и других научных дисциплинах. В отличие от одномерных интегралов, вычисление многомерных интегралов сопряжено с рядом сложностей, включая рост вычислительных затрат с увеличением размерности задачи. Для эффективного решения таких задач используются численные методы, например, метод Симпсона, который является одной из популярных многошаговых схем.

Метод Симпсона основан на аппроксимации функции на интервале с помощью парабол и обеспечивает высокую точность вычислений при относительно небольшом количестве разбиений. Его применение в многомерных задачах требует многократного повторения расчетов по всем измерениям, что делает задачу вычислительно интенсивной. Для оптимизации этих вычислений целесообразно использовать параллельные вычисления.

Целью данной работы является разработка последовательной и параллельной программ для вычисления многомерных интегралов с использованием метода Симпсона. В параллельной реализации используется библиотека MPI (Message Passing Interface), которая позволяет эффективно распределять вычисления между несколькими процессами.

Задачи данной работы:
\begin{enumerate}
    \item Реализовать последовательную программу для вычисления многомерных интегралов методом Симпсона.
    \item Разработать параллельную программу с использованием MPI для ускорения вычислений.
    \item Провести сравнение производительности последовательной и параллельной реализаций на различных тестовых данных.
\end{enumerate}

\newpage

\section*{Постановка задачи}  
\addcontentsline{toc}{section}{Постановка задачи}  

Задача вычисления многомерного интеграла состоит в нахождении значения интеграла функции \( f(x_1, x_2, \ldots, x_n) \), заданной на \( n \)-мерной области \( D \):

\[
I = \int\limits_{D} f(x_1, x_2, \ldots, x_n) \, dV,
\]

где \( dV = dx_1 dx_2 \cdots dx_n \) представляет элемент объема. Для упрощения области интегрирования \( D \) предполагается, что она является прямоугольным параллелепипедом:

\[
D = [a_1, b_1] \times [a_2, b_2] \times \cdots \times [a_n, b_n].
\]

Таким образом, задача сводится к вычислению следующего выражения:

\[
I = \int\limits_{a_1}^{b_1} \int\limits_{a_2}^{b_2} \cdots \int\limits_{a_n}^{b_n} f(x_1, x_2, \ldots, x_n) \, dx_1 dx_2 \cdots dx_n.
\]

Численное решение этой задачи требует дискретизации области интегрирования и аппроксимации функции \( f \) на сетке. Метод Симпсона используется для этой цели и основывается на приближении интеграла через значения функции в узлах сетки. Для одномерного случая метод выражается как:

\[
\int\limits_a^b f(x) \, dx \approx \frac{h}{3} \left( f(a) + 4 \sum_{i=1, \, \text{нечетн.}}^{n-1} f(x_i) + 2 \sum_{i=2, \, \text{четн.}}^{n-2} f(x_i) + f(b) \right),
\]

где \( h = \frac{b-a}{n} \) — шаг сетки, а \( x_i = a + i \cdot h \) — узлы сетки.

Для многомерного случая метод Симпсона применяется итеративно по каждому измерению. Обозначив число разбиений по \( k \)-й координате как \( n_k \) и шаг \( h_k = \frac{b_k - a_k}{n_k} \), многомерный интеграл может быть вычислен как:

\[
I \approx \sum_{i_1=0}^{n_1} \sum_{i_2=0}^{n_2} \cdots \sum_{i_n=0}^{n_n} C(i_1, i_2, \ldots, i_n) \cdot f(x_{i_1}, x_{i_2}, \ldots, x_{i_n}) \cdot h_1 h_2 \cdots h_n,
\]

где \( C(i_1, i_2, \ldots, i_n) \) — коэффициенты метода Симпсона, зависящие от положения узлов (крайние, четные или нечетные индексы).

Целью данной работы является реализация алгоритма численного интегрирования с использованием метода Симпсона в двух вариантах:
\begin{enumerate}
    \item Последовательная программа, выполняющая расчеты на одном процессоре.
    \item Параллельная программа с использованием библиотеки MPI для распределения вычислений между несколькими процессами.
\end{enumerate}

Задача также включает сравнение точности и производительности разработанных алгоритмов на тестовых функциях и областях интегрирования.

\newpage
\section*{Описание алгоритма}
\addcontentsline{toc}{section}{Описание алгоритма}
Для вычисления многомерного интеграла методом Симпсона алгоритм включает следующие этапы:

\begin{enumerate}
    \item \textbf{Дискретизация области интегрирования.}
    \begin{itemize}
        \item Определяются границы интегрирования для каждого измерения многомерного пространства.
        \item Каждое измерение делится на равные интервалы, что позволяет создать сетку точек в пространстве.
    \end{itemize}

    \item \textbf{Создание сетки точек.}
    \begin{itemize}
        \item Вычисляются координаты всех узлов сетки. Эти узлы определяются как комбинации всех возможных значений точек разбиения по каждому измерению.
    \end{itemize}

    \item \textbf{Вычисление коэффициентов метода Симпсона.}
    \begin{itemize}
        \item Для каждого узла сетки вычисляется его вес в соответствии с методом Симпсона:
        \begin{itemize}
            \item Если узел находится на границе интервала, ему присваивается вес \( 1 \).
            \item Если узел имеет нечётное положение вдоль своего измерения, его вес равен \( 4 \).
            \item Если узел имеет чётное положение (но не на границе), его вес равен \( 2 \).
        \end{itemize}
        \item Общий вес узла рассчитывается как произведение весов для всех измерений.
    \end{itemize}

    \item \textbf{Обход всех точек сетки.}
    \begin{itemize}
        \item Последовательно перебираются все узлы сетки, вычисляется значение функции в каждой точке.
        \item Полученное значение функции умножается на соответствующий вес узла, а результат добавляется к итоговой сумме.
    \end{itemize}

    \item \textbf{Масштабирование результата.}
    \begin{itemize}
        \item Итоговая сумма умножается на произведение шагов разбиения по всем измерениям и делится на 3 в степени размерности интеграла, что соответствует формуле метода Симпсона.
    \end{itemize}

    \item \textbf{Возврат результата.}
    \begin{itemize}
        \item Полученное значение округляется, если это необходимо, и возвращается как результат вычисления интеграла.
    \end{itemize}
\end{enumerate}

\textbf{Алгоритмическая сложность}  

Алгоритмическая сложность метода Симпсона для вычисления многомерного интеграла зависит от следующих факторов:

\begin{enumerate}
    \item \textbf{Дискретизация области интегрирования.}  
    \begin{itemize}
        \item Каждое измерение делится на \( n \) интервалов, что формирует \( (n+1) \) узлов вдоль этого измерения.
        \item Для \( d \)-мерного пространства общее число узлов равно \( (n+1)^d \), так как сетка создаётся путём перебора всех комбинаций точек по каждому измерению.  
    \end{itemize}
    Таким образом, сложность на этом этапе пропорциональна \( O(n^d) \).

    \item \textbf{Обход всех узлов сетки.}  
    \begin{itemize}
        \item Для каждой точки сетки производится вычисление функции в данной точке. 
        \item Общее количество точек равно \( (n+1)^d \), следовательно, сложность данного этапа также составляет \( O(n^d) \).
    \end{itemize}

    \item \textbf{Масштабирование результата.}  
    \begin{itemize}
        \item На этапе масштабирования выполняется лишь конечное количество операций, независимое от \( n \) или \( d \).  
        \item Сложность данного этапа равна \( O(1) \).
    \end{itemize}
\end{enumerate}

\noindent \textbf{Итоговая сложность:}  
Сложность алгоритма в целом определяется этапами дискретизации и обхода узлов, поэтому она пропорциональна:
\[
O(n^d),
\]
где \( n \) — количество делений по каждому измерению, а \( d \) — размерность пространства.

\noindent \textbf{Особенность:}  
\begin{itemize}
    \item Сложность экспоненциально растёт с увеличением размерности \( d \).

\end{itemize}

\newpage
\section*{Описание схемы распараллеливания} 
\addcontentsline{toc}{section}{Описание схемы распараллеливания}


Для распараллеливания алгоритма вычисления многомерных интегралов методом Симпсона на нескольких процессах, можно разделить задачу на несколько этапов.

\subsection*{Этапы распараллеливания}

\begin{enumerate}

    \item \textbf{Определение локальных разбиений.}
    Главный процесс (процесс с номером 0) рассчитывает локальное количество разбиений для каждого процесса. При этом, если количество разбиений нечетное, оно увеличивается на единицу, чтобы обеспечить четкость разбиений. Это значение затем передается всем остальным процессам.

    \item \textbf{Расчет локальных пределов интегрирования.}
    Главный процесс, исходя из общего диапазона интегрирования, делит его на части и отправляет каждому процессу соответствующие локальные пределы для интегрирования. Эти пределы определяются для каждой размерности задачи. Главный процесс отправляет пределы для каждой размерности всем остальным процессам, кроме себя.

    \item \textbf{Вычисление на каждом процессе.}
    Каждый процесс, получив локальные пределы, запускает вычисления с использованием метода Симпсона. Для этого каждому процессу передается соответствующий подмассив данных, который будет использоваться для вычислений в его части задачи. Каждый процесс вычисляет интеграл для своей части области.

    \item \textbf{Сбор результатов и агрегация.}
    После того как все процессы закончат вычисления, они отправляют свои локальные результаты обратно главному процессу, используя операции MPI. Главный процесс собирает все частичные результаты, и с помощью операции редукции суммирует их, получая итоговый результат интеграции.

    \item \textbf{Возвращение результата.}
    Финальный результат вычислений (интеграл) возвращается в главный процесс и выводится как итоговое значение. Все процессы завершили свою работу, и задача считается решенной.

\end{enumerate}
\subsection*{Основные операции и взаимодействие между процессами:}
\begin{itemize}
    \item \textbf{Распространение данных:} Для синхронизации информации между процессами используется операция передачи данных \texttt{broadcast}. Она позволяет всем процессам получать одинаковую информацию, такую как идентификатор функции и размерность задачи.
    \item \textbf{Отправка локальных данных:} Главный процесс делит диапазоны интегрирования и отправляет локальные пределы каждому процессу, используя операцию \texttt{send}.
    \item \textbf{Получение локальных данных:} Рабочие процессы получают свои локальные пределы от главного процесса с помощью операции \texttt{recv}.
    \item \textbf{Редукция результатов:} После вычислений каждый процесс отправляет свой результат главному процессу с помощью операции \texttt{reduce}, где результаты суммируются для получения итогового значения интеграла.
\end{itemize}

\noindent \textbf{Итоговая схема:} 
\begin{itemize}
    \item Главный процесс делит задачу на части и отправляет данные остальным процессам.
    \item Рабочие процессы выполняют локальные вычисления.
    \item Главный процесс собирает результаты и вычисляет итоговый результат.
\end{itemize} 

\newpage
\section*{Экспериментальное исследование}
\addcontentsline{toc}{section}{Экспериментальное исследование}

В ходе эксперимента была проведена оценка производительности последовательной и параллельной версии программы для вычисления многомерных интегралов методом Симпсона. Для сравнения использовалась двумерная задача интегрирования с пределами \([0, 1000]\) для каждой оси, с разбиением области на 1000 интервалов по каждой из осей. Это позволило оценить, насколько параллельная программа может ускорить вычисления на многопроцессной системе.

\subsection*{Результаты работы последовательной программы}

Последовательная программа была запущена с использованием параметров, указанных выше, и вычисление интеграла заняло 0.314093 секунд. Время работы последовательной программы служит базой для дальнейших сравнений.

\subsection*{Результаты работы параллельной программы}

Для параллельной версии программы использовались те же параметры задачи (интервалы \([0, 1000]\) по обеим осям, 1000 разбиений). Однако вычисления были распараллелены на четыре процесса. Время работы параллельной программы составило 0.0207756 секунд. Это означает, что каждый процесс обрабатывал меньшую часть интегрируемой области, значительно сокращая время выполнения по сравнению с последовательным методом.

\subsection*{Анализ ускорения}

Для оценки эффективности параллельного выполнения, мы вычислили ускорение программы, которое определяется как отношение времени работы последовательной программы к времени работы параллельной программы:

\[
\text{Ускорение} = \frac{T_{\text{последовательный}}}{T_{\text{параллельный}}}.
\]

На основе полученных данных ускорение составило примерно 15.1. Это означает, что параллельная программа на четырех процессах была в 15 раз быстрее последовательной программы.

\subsection*{Обсуждение результатов}

Результаты эксперимента показывают значительное улучшение производительности при использовании параллельной версии программы. Разделение задачи на несколько частей и выполнение вычислений на отдельных процессах позволило существенно уменьшить время выполнения. На четырёх процессах интегрирование с использованием метода Симпсона выполнялось в 15 раз быстрее, чем при последовательной обработке.

Это ускорение обусловлено возможностью разделить вычислительные ресурсы между несколькими процессами, что особенно эффективно при решении многомерных интегралов, где вычисления могут быть распределены по частям области интегрирования. При этом важно отметить, что на увеличение числа процессов и, соответственно, на уменьшение времени выполнения также влияет накладной расход на передачу данных между процессами. Однако даже с учётом этих затрат распараллеливание позволяет значительно повысить производительность.

Данные эксперименты демонстрируют потенциал использования параллельных вычислений для решения сложных вычислительных задач, таких как многомерные интегралы, что может быть полезно в различных областях науки и техники, где требуется обработка больших объемов данных за минимальное время.

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}

В ходе работы была реализована параллельная версия алгоритма вычисления многомерных интегралов методом Симпсона с использованием библиотеки MPI. Сравнение последовательной и параллельной версии программы показало значительное улучшение производительности при использовании многопроцессных систем.

Эксперименты с двухмерным интегралом, разбитым на 1000 блоков, показали, что параллельная программа на четырех процессах демонстрирует ускорение в 15 раз по сравнению с последовательной версией. Это подтверждает эффективность распараллеливания задачи, особенно для сложных вычислительных задач, где возможна значительная экономия времени при использовании многопроцессорных вычислений.

Таким образом, проведенная работа показала, что распараллеливание вычислений с помощью MPI позволяет существенно повысить эффективность решения многомерных интегралов и других вычислительных задач, что является важным шагом в оптимизации научных и инженерных расчетов.

\newpage

\begin{thebibliography}{1}
  \addcontentsline{toc}{section}{Литература}
  \bibitem{shell} Метод симпсона// URL: \url{https://www.youtube.com/watch?v=JXh9AQkKmsw}
  \bibitem{tehnical sciences} Алгоритм и формулы Симпсона на прямоугольнике и в параллелепипеде// URL: \url{https://elib.psu.by/bitstream/123456789/16528/1.pdf}
  \end{thebibliography}
\newpage

\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
\begin{lstlisting}
    namespace frolova_e_Simpson_method_mpi {
    double Simpson_Method(double (*func)(const std::vector<double>&), size_t divisions,
                                                    size_t dimension, std::vector<double>& limits) {
  std::vector<double> h(dimension);
  std::vector<int> steps(dimension);
  std::vector<int> nodes(dimension);
  std::vector<int> offset(dimension);

  std::vector<double> grid;
  int totalPoints = 0;

  for (size_t i = 0; i < dimension; ++i) {
    double a = limits[2 * i];
    double b = limits[2 * i + 1];

    steps[i] = divisions;
    nodes[i] = steps[i] + 1;
    h[i] = (b - a) / steps[i];

    offset[i] = totalPoints;

    for (int j = 0; j < nodes[i]; ++j) {
      grid.push_back(a + j * h[i]);
    }

    totalPoints += nodes[i];
  }

  std::vector<int> indices(dimension, 0);
  std::vector<double> point(dimension);
  double integral = 0.0;

  int totalIterations = 1;
  for (size_t i = 0; i < dimension; ++i) {
    totalIterations *= nodes[i];
  }

  for (int linearIndex = 0; linearIndex < totalIterations; ++linearIndex) {
    int temp = linearIndex;

    for (size_t i = 0; i < dimension; ++i) {
      indices[i] = temp % nodes[i];
      temp /= nodes[i];
    }

    for (size_t i = 0; i < dimension; ++i) {
      point[i] = grid[offset[i] + indices[i]];
    }

    double weight = 1.0;
    for (size_t i = 0; i < dimension; ++i) {
      if (indices[i] == 0 || indices[i] == steps[i])
        weight *= 1.0;
      else if (indices[i] % 2 == 1)
        weight *= 4.0;
      else
        weight *= 2.0;
    }

    integral += weight * func(point);
  }

  for (size_t i = 0; i < dimension; ++i) {
    integral *= h[i] / 3.0;
  }

  return roundToTwoDecimalPlaces(integral);
}

bool SimpsonmethodParallel::pre_processing() {
  internal_order_test();

  if (world.rank() == 0) {
    // Init value for input and output
    int* value = reinterpret_cast<int*>(taskData->inputs[0]);  //{divisions,dimension,functionid}
    divisions = static_cast<size_t>(value[0]);
    dimension = static_cast<size_t>(value[1]);
    functionid = static_cast<size_t>(value[2]);

    auto* value_2 = reinterpret_cast<double*>(taskData->inputs[1]);
    for (int i = 0; i < static_cast<int>(taskData->inputs_count[1]); i++) {
      limits.push_back(value_2[i]);
    }
  }

  return true;
}

bool validation() {
  internal_order_test();

  if (world.rank() == 0) {
    int* value = reinterpret_cast<int*>(taskData->inputs[0]);
    if (taskData->inputs_count[0] != 3) {
      return false;
    }

    auto div = static_cast<size_t>(value[0]);
    if (static_cast<int>(div) % 2 != 0) {
      return false;
    }

    auto dim = static_cast<size_t>(value[1]);
    if (taskData->inputs_count[1] / dim != 2) {
      return false;
    }
  }
  return true;
}

bool SimpsonmethodParallel::run() {
  internal_order_test();

  broadcast(world, functionid, 0);
  broadcast(world, dimension, 0);

  if (world.rank() == 0) {
    localdivisions = divisions / world.size();
    if (localdivisions % 2 != 0) {
      localdivisions++;
    }
  }
  broadcast(world, localdivisions, 0);

  if (world.rank() == 0) {
    size_t size = world.size();

    for (size_t i = 0; i < size; i++) {
      std::vector<double> loclim;

      for (size_t j = 0; j < dimension; j++) {
        double a = limits[2 * j];
        double b = limits[2 * j + 1];
        double step = (b - a) / size;

        double lim1;
        double lim2;

        if (j == 0) {
          lim1 = a + i * step;
          if (i < size - 1) {
            lim2 = a + (i + 1) * step;
          } else {
            lim2 = b;
          }
        } else {
          lim1 = a;
          lim2 = b;
        }

        if (i == 0) {
          localLimits.push_back(lim1);
          localLimits.push_back(lim2);
        } else {
          loclim.push_back(lim1);
          loclim.push_back(lim2);
        }
      }

      if (i != 0) {
        world.send(i, 0, loclim);
      }
    }
  }

  if (world.rank() != 0) {
    world.recv(0, 0, localLimits);
  }

  func = functionRegistry[functionid];

  localres = frolova_e_Simpson_method_mpi::Simpson_Method(func, localdivisions, dimension, localLimits);

  reduce(world, localres, resIntegral, std::plus<>(), 0);

  return true;
}

bool SimpsonmethodParallel::post_processing() {
  internal_order_test();

  if (world.rank() == 0) {
    reinterpret_cast<double*>(taskData->outputs[0])[0] = resIntegral;
  }

  return true;
}
\end{lstlisting}


\end{document}
