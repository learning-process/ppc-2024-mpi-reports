\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{indentfirst}
\geometry{top=2cm,bottom=2cm,left=2cm,right=2cm}
\lstset{
  language=C++, 
  basicstyle=\ttfamily\small, 
  numbers=left, 
  numberstyle=\tiny, 
  stepnumber=1, 
  tabsize=4, 
  breaklines=true, 
  frame=single, 
  captionpos=b 
}


\titleformat{\section}[block]{\bfseries\large\centering}{\thesection.}{1em}{}
\titleformat{\subsection}[block]{\bfseries\normalsize}{\thesubsection.}{1em}{}

\title{
\vspace{6cm}
\textbf{\Large Отчет по лабораторной работе}\\[0.5cm]
\textbf{\Large Вариант 21}\\
\textbf{\Large Поразрядная сортировка с четно-нечетным слиянием Бэтчера} \\[1.0cm]
}
\author{
\textbf{Студент:} Козлова Екатерина ФИ3\\[0.2cm]
\textbf{Преподаватель:} Сысоев А.В., доцент кафедры ВВСП \\[5cm]
}
\date{}

\begin{document}

\maketitle
\vfill
\begin{center}
\textbf{\normalsize Нижний Новгород, 2024}
\end{center}

\newpage

\section*{\centering Введение}

Алгоритмы сортировки представляют собой одну из наиболее фундаментальных задач вычислительной математики и информатики. Среди них поразрядная сортировка занимает особое место, так как позволяет обрабатывать большие объемы данных за линейное время в зависимости от числа элементов и длины их битового представления. В данной работе рассматривается модификация поразрядной сортировки, предназначенная для вещественных чисел, с распараллеливанием вычислений и четно-нечетным слиянием Бэтчера. 

Цель работы — разработать последовательную и параллельную версии поразрядной сортировки для вещественных чисел типа \texttt{double}, протестировать их корректность и провести сравнительный анализ производительности.

\newpage

\section*{\centering Постановка задачи}

Целью данной лабораторной работы является исследование и реализация алгоритма поразрядной сортировки с четно-нечетным слиянием Бэтчера для вещественных чисел. Основные этапы задачи:
\begin{enumerate}
    \item Разработка последовательного алгоритма поразрядной сортировки, поддерживающего корректную работу с числами типа \texttt{double}, включая отрицательные значения.
    \item Построение параллельной версии алгоритма с использованием четно-нечетного слияния Бэтчера для объединения отсортированных частей массива.
    \item Использование библиотеки \texttt{Boost MPI} для эффективного распределения вычислений между несколькими процессами.
    \item Проведение серии экспериментов для оценки производительности алгоритмов: последовательного и параллельного.
    \item Сравнение результатов и анализ эффективности параллелизации.
\end{enumerate}

Успешное выполнение задачи должно продемонстрировать прирост производительности параллельного подхода и подтвердить его корректность.

\newpage

\section*{\centering Описание алгоритма}

Поразрядная сортировка (Radix Sort) — алгоритм сортировки, который сортирует числа путем обработки отдельных разрядов их представления, начиная с младшего и заканчивая старшим. Основная идея заключается в использовании стабильной сортировки на каждом разряде. Выполняется за линейное время.

Особенности алгоритма:
\begin{itemize}
    \item Для вещественных чисел используется преобразование: каждый элемент массива преобразуется в его 64-битное представление, что позволяет работать с числами на уровне их битов. Для корректной сортировки отрицательных чисел старший бит (бит знака) инвертируется, чтобы все отрицательные числа были обработаны как положительные, не нарушая общей логики сортировки. Это обеспечивает корректное поведение сортировки.
    \item Сложность алгоритма составляет \(O(kn)\), где \(n\) — количество элементов, \(k\) — их длина (количесто разрядов).
    \item Четно-нечетное слияние Бэтчера применяется в параллельной версии для объединения отсортированных частей данных. Этот метод основан на разбиении массива и последовательном объединении соседних блоков.
\end{itemize}

Алгоритм в данном проекте позволяет работать с вещественными числами типа \texttt{double}, что увеличивает его сложность, но позволяет обрабатывать реалистичные наборы данных.

\newpage

\section*{\centering Описание схемы распараллеливания}

Распараллеливание реализовано с использованием библиотеки \texttt{Boost MPI}, которая предоставляет инструменты для обмена данными между процессами. Основные этапы распараллеливания:
\begin{enumerate}
    \item \textbf{Разделение данных}:
    Главный процесс делит исходный массив на части, равные числу процессов, с использованием функции \texttt{scatterv}. Это позволяет равномерно распределить данные между узлами.
    \item \textbf{Локальная обработка}:
    Каждый процесс выполняет поразрядную сортировку своей части массива.
    \item \textbf{Обмен данными}:
    Для упорядочивания элементов во всем массиве процессы обмениваются данными своих подмассивов с соседними процессами, что позволяет постепенно улучшать сортировку всего набора данных.
    \item \textbf{Слияние Бэтчера}:
    Реализуется многопроцессное объединение данных с использованием четно-нечетного алгоритма. Суть метода заключается в чередующемся слиянии данных между процессами на разных этапах.
    На каждом шаге один процесс будет обмениваться данными с другим, причем очередность этого обмена зависит от фазы слияния (чётная или нечётная).
    \item \textbf{Сбор результатов}:
    После выполнения всех операций данные собираются обратно на главном процессе с использованием функции \texttt{gatherv}.
\end{enumerate}

Схема позволяет эффективно использовать ресурсы вычислительной системы и минимизировать затраты на синхронизацию.

\newpage

\section*{\centering MPI-версия: описание программной реализации}

Программная реализация алгоритма использует библиотеку \texttt{Boost MPI} и включает:
\begin{enumerate}
    \item Инициализацию MPI и распределение данных между процессами.
    \item Преобразование данных в битовое представление для поразрядной сортировки.
    \item Реализацию четно-нечетного слияния для объединения отсортированных данных.
    \item Сбор данных на главном процессе и преобразование их в исходный формат.
\end{enumerate}

\newpage

\section*{\centering Результаты экспериментов}

Эксперименты проводились на вычислительном кластере с 4 процессами. Тестовые данные:
\begin{itemize}
    \item Размер массива: 1 000 000 элементов.
    \item Тип данных: случайные вещественные числа в диапазоне [-100.0, 100.0].
\end{itemize}

Результаты:
\begin{itemize}
    \item Последовательная версия:
    \begin{itemize}
        \item Время выполнения для 1 000 000 элементов: 4.3 секунды.
    \end{itemize}
    \item Параллельная версия:
    \begin{itemize}
        \item Время выполнения для 1 000 000 элементов на 4 процессах: 0.99 секунды.
    \end{itemize}
\end{itemize}

\newpage

\section*{\centering Заключение}

Работа подтвердила преимущества параллельного подхода для сортировки больших объемов данных. Полученные результаты показывают, что использование четно-нечетного слияния эффективно снижает время выполнения, сохраняя корректность обработки.

\newpage

\section*{\centering Приложение}
\begin{lstlisting}[language=C++,caption={Код программы}]
#include <boost/mpi/collectives.hpp>
#include <boost/mpi/communicator.hpp>
#include <memory>
#include <numeric>
#include <utility>
#include <vector>

#include "core/task/include/task.hpp"

namespace kozlova_e_radix_batcher_sort_mpi {

class RadixBatcherSortSequential : public ppc::core::Task {
 public:
  explicit RadixBatcherSortSequential(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
  bool pre_processing() override;
  bool validation() override;
  bool run() override;
  bool post_processing() override;

 private:
  int input_size{};
  std::vector<double> data;

  static void radixSort(std::vector<double>& a);
};

class RadixBatcherSortMPI : public ppc::core::Task {
 public:
  explicit RadixBatcherSortMPI(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
  bool pre_processing() override;
  bool validation() override;
  bool run() override;
  bool post_processing() override;

 private:
  std::vector<double> input_;
  int input_size{};
  boost::mpi::communicator world;

  static void radixSort(std::vector<double>& a);
  void RadixSortWithOddEvenMerge(std::vector<double>& a);
};

}  // namespace kozlova_e_radix_batcher_sort_mpi
#include <boost/serialization/vector.hpp>
#include <cstring>
#include <vector>

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortSequential::pre_processing() {
  internal_order_test();
  input_size = taskData->inputs_count[0];
  data.resize(input_size);
  auto* mas = reinterpret_cast<double*>(taskData->inputs[0]);
  for (int i = 0; i < input_size; i++) data[i] = mas[i];
  return true;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortSequential::validation() {
  internal_order_test();
  return taskData->inputs_count[0] == taskData->outputs_count[0] && taskData->inputs_count[0] >= 0;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortSequential::run() {
  internal_order_test();
  radixSort(data);
  return true;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortSequential::post_processing() {
  internal_order_test();
  for (size_t i = 0; i < data.size(); i++) reinterpret_cast<double*>(taskData->outputs[0])[i] = data[i];
  return true;
}

void kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortSequential::radixSort(std::vector<double>& a) {
  std::vector<uint64_t> bit_representation(a.size());

  for (size_t i = 0; i < a.size(); ++i) {
    uint64_t bits = *reinterpret_cast<uint64_t*>(&a[i]);
    if ((bits >> 63) != 0u) {
      bit_representation[i] = ~bits;
    } else {
      bit_representation[i] = bits | 0x8000000000000000;
    }
  }

  for (int bit = 0; bit < 64; ++bit) {
    std::vector<uint64_t> output(a.size());
    int count[2] = {0};

    for (size_t i = 0; i < bit_representation.size(); ++i) {
      count[(bit_representation[i] >> bit) & 1]++;
    }

    count[1] += count[0];

    for (int i = bit_representation.size() - 1; i >= 0; --i) {
      int val = (bit_representation[i] >> bit) & 1;
      output[--count[val]] = bit_representation[i];
    }

    bit_representation = output;
  }

  for (size_t i = 0; i < a.size(); ++i) {
    uint64_t bits = bit_representation[i];
    if ((bits & 0x8000000000000000) != 0u) {
      bits &= ~0x8000000000000000;
    } else {
      bits = ~bits;
    }
    memcpy(&a[i], &bits, sizeof(double));
  }
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::pre_processing() {
  internal_order_test();
  if (world.rank() == 0) {
    input_size = taskData->inputs_count[0];
    input_.resize(input_size);
    auto* mas = reinterpret_cast<double*>(taskData->inputs[0]);
    for (int i = 0; i < input_size; i++) input_[i] = mas[i];
  }
  return true;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::validation() {
  internal_order_test();
  return world.rank() == 0 ? (taskData->inputs_count[0] == taskData->outputs_count[0] && taskData->inputs_count[0] >= 0)
                           : true;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::run() {
  internal_order_test();
  boost::mpi::broadcast(world, input_size, 0);
  RadixSortWithOddEvenMerge(input_);
  return true;
}

bool kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::post_processing() {
  internal_order_test();
  if (world.rank() == 0) {
    auto* output = reinterpret_cast<double*>(taskData->outputs[0]);
    for (size_t i = 0; i < input_.size(); i++) output[i] = input_[i];
  }
  return true;
}

void kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::radixSort(std::vector<double>& a) {
  std::vector<uint64_t> bit_representation(a.size());

  for (size_t i = 0; i < a.size(); ++i) {
    uint64_t bits = *reinterpret_cast<uint64_t*>(&a[i]);
    if ((bits >> 63) != 0u) {
      bit_representation[i] = ~bits;
    } else {
      bit_representation[i] = bits | 0x8000000000000000;
    }
  }

  for (int bit = 0; bit < 64; ++bit) {
    std::vector<uint64_t> output(a.size());
    int count[2] = {0};

    for (size_t i = 0; i < bit_representation.size(); ++i) {
      count[(bit_representation[i] >> bit) & 1]++;
    }

    count[1] += count[0];

    for (int i = bit_representation.size() - 1; i >= 0; --i) {
      int val = (bit_representation[i] >> bit) & 1;
      output[--count[val]] = bit_representation[i];
    }

    bit_representation = output;
  }

  for (size_t i = 0; i < a.size(); ++i) {
    uint64_t bits = bit_representation[i];
    if ((bits & 0x8000000000000000) != 0u) {
      bits &= ~0x8000000000000000;
    } else {
      bits = ~bits;
    }
    memcpy(&a[i], &bits, sizeof(double));
  }
}

void kozlova_e_radix_batcher_sort_mpi::RadixBatcherSortMPI::RadixSortWithOddEvenMerge(std::vector<double>& a) {
  a.resize(input_size);
  boost::mpi::broadcast(world, a.data(), a.size(), 0);

  int total_size = a.size();
  int num_processes = world.size();
  int local_size = total_size / num_processes;
  int remainder = total_size % num_processes;

  std::vector<int> send_counts(num_processes, local_size);
  for (int i = 0; i < remainder; ++i) {
    send_counts[i]++;
  }

  std::vector<int> send_displacements(num_processes, 0);
  for (int i = 1; i < num_processes; ++i) {
    send_displacements[i] = send_displacements[i - 1] + send_counts[i - 1];
  }

  std::vector<double> local_input(send_counts[world.rank()]);

  boost::mpi::scatterv(world, a.data(), send_counts, send_displacements, local_input.data(), send_counts[world.rank()],
                       0);

  radixSort(local_input);

  int step = 1;
  bool is_even_phase = true;

  while (step <= world.size()) {
    int partner = -1;
    radixSort(local_input);
    if (is_even_phase) {
      if (world.rank() % 2 == 0 && world.rank() + 1 < world.size()) {
        partner = world.rank() + 1;
      } else if (world.rank() % 2 != 0) {
        partner = world.rank() - 1;
      }
    } else {
      if (world.rank() % 2 != 0 && world.rank() + 1 < world.size()) {
        partner = world.rank() + 1;
      } else if (world.rank() % 2 == 0 && world.rank() > 0) {
        partner = world.rank() - 1;
      }
    }

    if (partner != -1) {
      std::vector<double> recv_data(local_input.size());
      world.sendrecv(partner, 0, local_input, partner, 0, recv_data);

      std::vector<double> merged(local_input.size() + recv_data.size());
      std::merge(local_input.begin(), local_input.end(), recv_data.begin(), recv_data.end(), merged.begin());

      radixSort(merged);

      int local_keep = send_counts[world.rank()];

      if (world.rank() < partner) {
        local_input.assign(merged.begin(), merged.begin() + local_keep);
      } else {
        local_input.assign(merged.end() - local_keep, merged.end());
      }
    }

    is_even_phase = !is_even_phase;
    step++;
  }

  boost::mpi::gatherv(world, local_input.data(), send_counts[world.rank()], a.data(), send_counts, send_displacements,
                      0);
}
\end{lstlisting}
\end{document}