\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{indentfirst}
\geometry{top=2cm,bottom=2cm,left=2cm,right=2cm}
\lstset{
  language=C++, 
  basicstyle=\ttfamily\small, 
  numbers=left, 
  numberstyle=\tiny, 
  stepnumber=1, 
  tabsize=4, 
  breaklines=true, 
  frame=single, 
  captionpos=b 
}


\titleformat{\section}[block]{\bfseries\large\centering}{\thesection.}{1em}{}
\titleformat{\subsection}[block]{\bfseries\normalsize}{\thesubsection.}{1em}{}

\title{
\vspace{4cm}
\textbf{\Large Отчет по лабораторной работе}\\[1cm]
\textbf{\Large Быстрая сортировка с простым слиянием} \\[1cm]
\textbf{\Large Вариант 14}\\[5cm]
}
\author{
\textbf{Студент:} Ясакова Татьяна ФИ2\\[0.2cm]
\textbf{Преподаватель:} Сысоев А.В., доцент кафедры ВВСП \\[5cm]
}
\date{}

\begin{document}

\maketitle
\vfill
\begin{center}
\textbf{\normalsize Нижний Новгород, 2024}
\end{center}

\newpage

\section*{\centering Введение}

Сортировка - одна из фундаментальных задач в области информатики и программирования. Эффективные алгоритмы сортировки играют ключевую роль в оптимизации производительности многих компьютерных систем и приложений. Два широко используемых и эффективных алгоритма сортировки - это быстрая сортировка (quicksort) и простое слияние (merge sort).

Быстрая сортировка является одним из самых популярных и эффективных алгоритмов сортировки. Она отличается своей производительностью, особенно при работе с большими объемами данных. Однако, в некоторых случаях, быстрая сортировка может показывать худшую производительность, особенно при наличии упорядоченных или почти упорядоченных данных.

В свою очередь, простое слияние является стабильным алгоритмом сортировки, который эффективен при работе с данными, имеющими определенную структуру. Он работает путем разделения массива на две половины, сортировки каждой половины и последующего слияния отсортированных половин.

Цель работы — разработать последовательную и параллельную версии быстрой сортировки с простым слиянием, протестировать их корректность и провести сравнительный анализ производительности.

\newpage

\section*{\centering Постановка задачи}

Целью данной работы является исследование и реализация алгоритма "быстрая сортировка с простым слиянием" для эффективной сортировки массивов данных.
Основные задачи:
\begin{enumerate}
    \item Реализовать последовательный алгоритм быстрой сортировки с простым слиянием для упорядочивания данных.
    \item Разработать параллельную версию алгоритма с использованием библиотеки MPI.
    \item Провести функциональное тестирование алгоритма, сравнив результаты последовательной и параллельной версий.
    \item Сравнить производительность задачи при увеличении количества процессов.
    \item Подготовить подробный отчет.
\end{enumerate}

Успешное выполнение задачи должно продемонстрировать прирост производительности параллельного подхода и подтвердить его корректность.

\newpage

\section*{\centering Описание алгоритма}

Предложенный алгоритм представляет собой реализацию комбинированного метода "Быстрая сортировка с простым слиянием", выполненную на языке C++.

Функция слияния (merge). Алгоритм содержит вспомогательную функцию merge, которая отвечает за объединение двух отсортированных массивов в один.
Ключевые шаги этой функции:
\begin{itemize}
    \item Создается результирующий вектор result, размер которого заранее резервируется для повышения производительности.
    \item Поочередно сравниваются текущие элементы исходных массивов left и right, и меньший элемент добавляется в result, а соответствующий индекс инкрементируется.
    \item После завершения одной из исходных последовательностей, оставшиеся элементы другой последовательности добавляются в конец result.
\end{itemize}

Функция быстрой сортировки с простым слиянием. Основная функция алгоритма реализует рекурсивный процесс быстрой сортировки с использованием простого слияния:
\begin{itemize}
    \item Если массив состоит из одного элемента или пуст, он возвращается без изменений.
    \item Выбирается опорный элемент (pivot) как середина массива.
    \item Массив делится на три части: left - элементы меньше опорного, right - элементы больше опорного, equal - элементы, равные опорному.
    \item Для частей left и right рекурсивно вызывается функция быстрой сортировки с простым слиянием.
    \item После сортировки частичных массивов, они последовательно объединяются с помощью функции merge, чтобы получить итоговый отсортированный массив.

Таким образом, алгоритм сочетает в себе преимущества быстрой сортировки и простого слияния, рекурсивно разделяя массив на части, сортируя их и объединяя обратно.
\end{itemize}

\newpage

\section*{\centering Описание схемы распараллеливания}

Распараллеливание реализовано с использованием библиотеки \texttt{Boost MPI}, которая предоставляет инструменты для обмена данными между процессами. Основные этапы распараллеливания:
\begin{enumerate}
    \item \textbf{Разделение данных}:
    Главный процесс делит исходный массив на части, равные числу процессов. Это позволяет равномерно распределить данные между узлами.
    \item \textbf{Локальная обработка}:
    Каждый процесс выполняет локальную сортировку своей части массива, используя последовательную версию алгоритма быстрой сортировки.
    \item \textbf{Обмен данными}:
    Результаты локальной сортировки собираются и объединяются в один отсортированный массив, используя алгоритм слияния.
\end{enumerate}

Схема позволяет эффективно использовать ресурсы вычислительной системы и минимизировать затраты на синхронизацию.

\newpage

\section*{\centering MPI-версия: описание программной реализации}

Программная реализация алгоритма использует библиотеки \texttt{MPI} и включает:
\begin{enumerate}
    \item Инициализацию MPI и распределение данных между процессами.
    \item Каждый процесс получает свой подмассив, который затем сортируется локально с использованием последовательной версии быстрой сортировки.
    \item Корневой процесс объединяет результаты с помощью алгоритма простого слияния.
    \item  Итоговый массив формируется на главном процессе.
\end{enumerate}

\newpage

\section*{\centering Результаты экспериментов}

На основе выполнения тестов для параллельной версии (на 2, 3, 4, 6, 8, 10 и 12 процессах) была создана следующая таблица:

\begin{tabular}{|c|c|c|c|}
    \hline
    Число процессов & Вид теста      & Время выполнения (с) & Ускорение \\ \hline
    1               & pipeline\_run & 1.163               & 1      \\ \hline
    1               & task\_run     & 1.24                & 1      \\ \hline
    2               & pipeline\_run & 1.560                & 0.755513      \\ \hline
    2               & task\_run     & 1.666                & 0.734298      \\ \hline
    3               & pipeline\_run & 0.490                & 2.383469      \\ \hline
    3               & task\_run     & 0.514                & 2.422451      \\ \hline
    4               & pipeline\_run & 0.420               & 2.779048     \\ \hline
    4               & task\_run     & 0.453                & 2.747308      \\ \hline
    6              & pipeline\_run & 0.311                & 3.749550      \\ \hline
    6              & task\_run     & 0.325                & 3.915385      \\ \hline
    8              & pipeline\_run & 0.424                & 2.842925      \\ \hline
    8              & task\_run     & 0.453                & 2.837308      \\ \hline
    10              & pipeline\_run & 0.367                & 3.268937      \\ \hline
    10              & task\_run     & 0.382                & 3.256073      \\ \hline
    12              & pipeline\_run & 0.326                & 3.547485      \\ \hline
    12              & task\_run     & 0.353                & 3.412748      \\ \hline
\end{tabular}

\newpage

\section*{\centering Заключение}

Результаты показывают, что увеличение количества процессов приводит к уменьшению времени выполнения, что свидетельствует о высокой эффективности распараллеливания.

Таким образом, MPI-реализация показала хорошую масштабируемость и значительное снижение времени выполнения по сравнению с последовательной реализацией.


\newpage

\section*{\centering Приложение}
\begin{lstlisting}[language=C++,caption={Код программы}]
#include <gtest/gtest.h>
#include <boost/mpi/collectives.hpp>
#include <boost/mpi/communicator.hpp>
#include "core/task/include/task.hpp"

namespace yasakova_t_quick_sort_with_simple_merge_mpi {

void quicksort_iterative(std::vector<int>& data);
void mpi_worker_function(boost::mpi::communicator& world, const std::vector<int>& local_data);
std::vector<int> master_function(boost::mpi::communicator& world, const std::vector<int>& local_data,
                                 const std::vector<int>& element_sizes);
void mpi_merge_function(boost::mpi::communicator& world, const std::vector<int>& local_data,
                        const std::vector<int>& element_sizes, std::vector<int>& res);

class SimpleMergeQuicksort : public ppc::core::Task {
 public:
  explicit SimpleMergeQuicksort(std::shared_ptr<ppc::core::TaskData> taskData_) : Task(std::move(taskData_)) {}
  bool pre_processing() override;
  bool validation() override;
  bool run() override;
  bool post_processing() override;

 private:
  int size_of_vector;
  std::vector<int> original_vector;
  std::vector<int> partitioned_vector;
  std::vector<int> element_sizes;
  std::vector<int> displacement;
  boost::mpi::communicator world;
};

}  // namespace yasakova_t_quick_sort_with_simple_merge_mpi


#include <boost/serialization/array.hpp>
#include <boost/serialization/vector.hpp>
#include <queue>
#include <stack>

namespace yasakova_t_quick_sort_with_simple_merge_mpi {
struct PriorityQueueNode {
  int key;
  int origin_rank;

  bool operator>(const PriorityQueueNode& other) const { return key > other.key; }
};

void mpi_worker_function(boost::mpi::communicator& world, const std::vector<int>& local_data) {
  int size = local_data.size();

  if (!local_data.empty()) {
    world.send(0, 0, local_data[0]);
  }

  for (int i = 1; i < size; ++i) {
    world.recv(0, 1);
    world.send(0, 0, local_data[i]);
  }
}

std::vector<int> master_function(boost::mpi::communicator& world, const std::vector<int>& local_data,
                                 const std::vector<int>& element_sizes) {
  std::priority_queue<PriorityQueueNode, std::vector<PriorityQueueNode>, std::greater<>> min_heap;
  std::vector<int> remaining_element_sizes = element_sizes;
  std::vector<int> result;
  int iter = 0;

  min_heap.push({local_data[iter++], 0});
  remaining_element_sizes[0]--;
  for (int i = 1; i < world.size(); ++i) {
    if (remaining_element_sizes[i] > 0) {
      int key;
      world.recv(i, 0, key);
      min_heap.push({key, i});
      remaining_element_sizes[i]--;
    }
  }

  while (!min_heap.empty()) {
    PriorityQueueNode node = min_heap.top();
    min_heap.pop();
    result.push_back(node.key);
    if (node.origin_rank == 0 && remaining_element_sizes[0] > 0) {
      min_heap.push({local_data[iter++], node.origin_rank});
      remaining_element_sizes[0]--;
    } else {
      if (remaining_element_sizes[node.origin_rank] > 0) {
        world.send(node.origin_rank, 1);
        int next_key;
        world.recv(node.origin_rank, 0, next_key);
        min_heap.push({next_key, node.origin_rank});
        remaining_element_sizes[node.origin_rank]--;
      }
    }
  }

  return result;
}

void mpi_merge_function(boost::mpi::communicator& world, const std::vector<int>& local_data,
                        const std::vector<int>& element_sizes, std::vector<int>& res) {
  if (world.rank() == 0) {
    res = master_function(world, local_data, element_sizes);
  } else {
    mpi_worker_function(world, local_data);
  }
  world.barrier();
}

void quicksort_iterative(std::vector<int>& data) {
  std::stack<std::pair<int, int>> stack;
  stack.emplace(0, data.size() - 1);

  while (!stack.empty()) {
    auto [low, high] = stack.top();
    stack.pop();

    if (low < high) {
      int pivot = data[high];
      int i = low - 1;

      for (int j = low; j < high; ++j) {
        if (data[j] < pivot) {
          std::swap(data[++i], data[j]);
        }
      }
      std::swap(data[i + 1], data[high]);
      int p = i + 1;

      stack.emplace(low, p - 1);
      stack.emplace(p + 1, high);
    }
  }
}

bool SimpleMergeQuicksort::validation() {
  internal_order_test();

  return *reinterpret_cast<int*>(taskData->inputs[0]) > 0;
}

bool SimpleMergeQuicksort::pre_processing() {
  internal_order_test();

  size_of_vector = *reinterpret_cast<int*>(taskData->inputs[0]);

  if (world.rank() == 0) {
    auto* vec_data = reinterpret_cast<int*>(taskData->inputs[1]);
    int vec_size = taskData->inputs_count[1];

    original_vector.assign(vec_data, vec_data + vec_size);
  }
  element_sizes.resize(world.size());
  displacement.resize(world.size());

  for (int i = 0; i < world.size(); ++i) {
    element_sizes[i] = size_of_vector / world.size() + (i < size_of_vector % world.size() ? 1 : 0);
    displacement[i] = (i == 0) ? 0 : displacement[i - 1] + element_sizes[i - 1];
  }

  partitioned_vector.resize(element_sizes[world.rank()]);

  return true;
}

bool SimpleMergeQuicksort::run() {
  internal_order_test();

  boost::mpi::scatterv(world, original_vector.data(), element_sizes, displacement, partitioned_vector.data(),
                       element_sizes[world.rank()], 0);

  quicksort_iterative(partitioned_vector);

  mpi_merge_function(world, partitioned_vector, element_sizes, original_vector);

  return true;
}

bool SimpleMergeQuicksort::post_processing() {
  internal_order_test();

  if (world.rank() == 0) {
    auto* out_vector = reinterpret_cast<int*>(taskData->outputs[0]);
    std::copy(original_vector.begin(), original_vector.end(), out_vector);
  }

  return true;
}

}  // namespace yasakova_t_quick_sort_with_simple_merge_mpi
\end{lstlisting}
\end{document}